{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffc23080",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-19 15:41:29.851213: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-19 15:41:29.860592: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-19 15:41:29.990869: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-19 15:41:29.993685: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-19 15:41:30.787259: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.io import arff\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sys.path.insert(0, f\"{os.path.dirname(os.getcwd())}/src\")\n",
    "from utils import evaluate_result\n",
    "from data_imbalance_src.smote_oversampling import RandomOversampling, ADASYNOversampling, BorderlineSMOTEOversampling, SMOTEOversampling, SVMSMOTEOversampling\n",
    "from data_imbalance_src.smote_oversampling import SMOTUNEDOversampling\n",
    "from data_imbalance_src.dazzle import DAZZLEOversampling\n",
    "from data_imbalance_src.Imbalance_Farou2022.data_generation import GANOversampling\n",
    "from data_imbalance_src.random_projection import RandomProjectionOversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2279378",
   "metadata": {},
   "source": [
    "# JavaScript_Vulnerability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad0cc5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = random.randint(0, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dddba0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file = f\"JS_Vuln_res_r1_rn{rs}.csv\"\n",
    "write_path = f\"{os.path.dirname(os.getcwd())}/result/{write_file}\"\n",
    "with open(write_path, \"w\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    csv_writer.writerow([\"oversampling_scheme\", \"runtime\", \"learner\", \"acc\", \"prec\", \"recall\", \"fpr\", \"f1\", \"auc\", \"g_score\", \"d2h\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7df5773e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JSVulnerabilityDataSet-1.0.csv']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = f\"{os.path.dirname(os.getcwd())}/data/JavaScript_Vulnerability/\"\n",
    "datafiles = [f for f in os.listdir(data_path) if f.endswith(\"csv\")]\n",
    "datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8d1bec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{data_path}/{datafiles[0]}\")\n",
    "drop_columns = [\"name\", \"longname\", \"path\", \"full_repo_path\", \"line\", \"column\", \"endline\", \"endcolumn\"]\n",
    "df = df.drop(drop_columns, axis=1)\n",
    "df = df.drop_duplicates()\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "625920be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CC</th>\n",
       "      <th>CCL</th>\n",
       "      <th>CCO</th>\n",
       "      <th>CI</th>\n",
       "      <th>CLC</th>\n",
       "      <th>CLLC</th>\n",
       "      <th>McCC</th>\n",
       "      <th>NL</th>\n",
       "      <th>NLE</th>\n",
       "      <th>CD</th>\n",
       "      <th>...</th>\n",
       "      <th>HVOC</th>\n",
       "      <th>HDIFF</th>\n",
       "      <th>HVOL</th>\n",
       "      <th>HEFF</th>\n",
       "      <th>HBUGS</th>\n",
       "      <th>HTIME</th>\n",
       "      <th>CYCL</th>\n",
       "      <th>PARAMS</th>\n",
       "      <th>CYCL_DENS</th>\n",
       "      <th>Vuln</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>10.250000</td>\n",
       "      <td>342.600759</td>\n",
       "      <td>3511.657780</td>\n",
       "      <td>0.114200</td>\n",
       "      <td>195.092099</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>893.594000</td>\n",
       "      <td>19212.271002</td>\n",
       "      <td>0.297865</td>\n",
       "      <td>1067.348389</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>1.928571</td>\n",
       "      <td>43.185065</td>\n",
       "      <td>83.285483</td>\n",
       "      <td>0.014395</td>\n",
       "      <td>4.626971</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>1.928571</td>\n",
       "      <td>43.185065</td>\n",
       "      <td>83.285483</td>\n",
       "      <td>0.014395</td>\n",
       "      <td>4.626971</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>8.703704</td>\n",
       "      <td>416.756269</td>\n",
       "      <td>3627.323084</td>\n",
       "      <td>0.138919</td>\n",
       "      <td>201.517949</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6266</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>142.623627</td>\n",
       "      <td>550.119705</td>\n",
       "      <td>0.047541</td>\n",
       "      <td>30.562206</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6267</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>75.284213</td>\n",
       "      <td>244.673691</td>\n",
       "      <td>0.025095</td>\n",
       "      <td>13.592983</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6268</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>724.297570</td>\n",
       "      <td>9995.306464</td>\n",
       "      <td>0.241433</td>\n",
       "      <td>555.294804</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>31.578947</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6269</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>6.071429</td>\n",
       "      <td>267.619433</td>\n",
       "      <td>1624.832274</td>\n",
       "      <td>0.089206</td>\n",
       "      <td>90.268460</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18.181818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6270</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>...</td>\n",
       "      <td>61</td>\n",
       "      <td>25.365854</td>\n",
       "      <td>1192.078205</td>\n",
       "      <td>30238.081294</td>\n",
       "      <td>0.397359</td>\n",
       "      <td>1679.893405</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6271 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CC  CCL  CCO  CI  CLC  CLLC  McCC  NL  NLE        CD  ...  HVOC  \\\n",
       "0     0.0    0    0   0  0.0     0     3   1    1  0.000000  ...    21   \n",
       "1     0.0    0    0   0  0.0     0    11   3    3  0.041667  ...    48   \n",
       "2     0.0    0    0   0  0.0     0     1   0    0  0.000000  ...    10   \n",
       "3     0.0    0    0   0  0.0     0     1   0    0  0.000000  ...    10   \n",
       "4     0.0    0    0   0  0.0     0     3   2    2  0.000000  ...    37   \n",
       "...   ...  ...  ...  ..  ...   ...   ...  ..  ...       ...  ...   ...   \n",
       "6266  0.0    0    0   0  0.0     0     2   1    1  0.000000  ...    20   \n",
       "6267  0.0    0    0   0  0.0     0     2   1    1  0.000000  ...    12   \n",
       "6268  0.0    0    0   0  0.0     0     6   4    4  0.000000  ...    49   \n",
       "6269  0.0    0    0   0  0.0     0     2   1    1  0.000000  ...    19   \n",
       "6270  0.0    0    0   0  0.0     0    16   3    2  0.027778  ...    61   \n",
       "\n",
       "          HDIFF         HVOL          HEFF     HBUGS        HTIME  CYCL  \\\n",
       "0     10.250000   342.600759   3511.657780  0.114200   195.092099     3   \n",
       "1     21.500000   893.594000  19212.271002  0.297865  1067.348389     9   \n",
       "2      1.928571    43.185065     83.285483  0.014395     4.626971     1   \n",
       "3      1.928571    43.185065     83.285483  0.014395     4.626971     1   \n",
       "4      8.703704   416.756269   3627.323084  0.138919   201.517949     3   \n",
       "...         ...          ...           ...       ...          ...   ...   \n",
       "6266   3.857143   142.623627    550.119705  0.047541    30.562206     2   \n",
       "6267   3.250000    75.284213    244.673691  0.025095    13.592983     2   \n",
       "6268  13.800000   724.297570   9995.306464  0.241433   555.294804     6   \n",
       "6269   6.071429   267.619433   1624.832274  0.089206    90.268460     2   \n",
       "6270  25.365854  1192.078205  30238.081294  0.397359  1679.893405    15   \n",
       "\n",
       "      PARAMS   CYCL_DENS  Vuln  \n",
       "0          2   30.000000     1  \n",
       "1          3   37.500000     1  \n",
       "2          4  100.000000     1  \n",
       "3          4  100.000000     0  \n",
       "4          3   30.000000     0  \n",
       "...      ...         ...   ...  \n",
       "6266       2   33.333333     0  \n",
       "6267       2   40.000000     0  \n",
       "6268       1   31.578947     1  \n",
       "6269       2   18.181818     0  \n",
       "6270       3   41.666667     1  \n",
       "\n",
       "[6271 rows x 36 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc09bb91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y value counts: \n",
      " 0    5367\n",
      "1     904\n",
      "Name: Vuln, dtype: int64\n",
      "y class ratio: 1: 6\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "print(\"y value counts: \\n\", str(y.value_counts()))\n",
    "print(\"y class ratio: 1:\", str(round(y.value_counts()[0]/y.value_counts()[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4055c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- y train classes count: \n",
      "0    4293\n",
      "1     723\n",
      "Name: Vuln, dtype: int64\n",
      "--- y train ratio: 1:6\n",
      " \n",
      "--- y test classes count: \n",
      "0    1074\n",
      "1     181\n",
      "Name: Vuln, dtype: int64\n",
      "--- y test ratio: 1:6\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=rs)\n",
    "print(\"--- y train classes count: \\n\" + str(y_train.value_counts()))\n",
    "print(\"--- y train ratio: 1:\" + str(round(y_train.value_counts()[0] / y_train.value_counts()[1])))\n",
    "print(\" \")\n",
    "print(\"--- y test classes count: \\n\" + str(y_test.value_counts()))\n",
    "print(\"--- y test ratio: 1:\" + str(round(y_test.value_counts()[0] / y_test.value_counts()[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c57ba8",
   "metadata": {},
   "source": [
    "# Moodle_Vulnerability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dd9fbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file = \"Moodle_Vuln_res_r10.csv\"\n",
    "write_path = f\"{os.path.dirname(os.getcwd())}/result/{write_file}\"\n",
    "with open(write_path, \"w\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    csv_writer.writerow([\"oversampling_scheme\", \"runtime\", \"learner\", \"acc\", \"prec\", \"recall\", \"fpr\", \"f1\", \"auc\", \"g_score\", \"d2h\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3e7482b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = f\"{os.path.dirname(os.getcwd())}/data/Vulnerable_Files/moodle-2_0_0-metrics.arff\"\n",
    "data = arff.loadarff(data_path)\n",
    "df = pd.DataFrame(data[0])\n",
    "df['IsVulnerable'] = df['IsVulnerable'].astype('str')\n",
    "d = {'b\\'yes\\'': 1, 'b\\'no\\'': 0}\n",
    "df['IsVulnerable'] = df['IsVulnerable'].astype(str).map(d).fillna(df['IsVulnerable'])\n",
    "df = df.drop_duplicates()\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcfe9983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nonecholoc</th>\n",
       "      <th>loc</th>\n",
       "      <th>nmethods</th>\n",
       "      <th>ccomdeep</th>\n",
       "      <th>ccom</th>\n",
       "      <th>nest</th>\n",
       "      <th>hvol</th>\n",
       "      <th>nIncomingCalls</th>\n",
       "      <th>nIncomingCallsUniq</th>\n",
       "      <th>nOutgoingInternCalls</th>\n",
       "      <th>nOutgoingExternFlsCalled</th>\n",
       "      <th>nOutgoingExternFlsCalledUniq</th>\n",
       "      <th>nOutgoingExternCallsUniq</th>\n",
       "      <th>IsVulnerable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>490.191513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1473.469064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>419.666089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2262.272730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1359.742007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2051</th>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113.676138</td>\n",
       "      <td>569.0</td>\n",
       "      <td>567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2052</th>\n",
       "      <td>61.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>539.859175</td>\n",
       "      <td>561.0</td>\n",
       "      <td>556.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2053</th>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>460.843316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.006064</td>\n",
       "      <td>568.0</td>\n",
       "      <td>567.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.163187</td>\n",
       "      <td>559.0</td>\n",
       "      <td>556.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2056 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      nonecholoc    loc  nmethods  ccomdeep  ccom  nest         hvol  \\\n",
       "0           58.0   58.0       0.0      12.0  12.0   2.0   490.191513   \n",
       "1           90.0  107.0       1.0      20.0  20.0   5.0  1473.469064   \n",
       "2           38.0   43.0       0.0       8.0   8.0   2.0   419.666089   \n",
       "3          130.0  130.0       0.0      26.0  26.0   4.0  2262.272730   \n",
       "4           96.0   96.0       1.0      13.0  13.0   5.0  1359.742007   \n",
       "...          ...    ...       ...       ...   ...   ...          ...   \n",
       "2051        20.0   20.0       3.0       1.0   1.0   0.0   113.676138   \n",
       "2052        61.0   61.0       5.0       8.0   8.0   2.0   539.859175   \n",
       "2053        43.0   43.0       0.0       6.0   6.0   1.0   460.843316   \n",
       "2054        19.0   19.0       3.0       1.0   1.0   0.0    95.006064   \n",
       "2055        21.0   21.0       3.0       1.0   1.0   0.0    82.163187   \n",
       "\n",
       "      nIncomingCalls  nIncomingCallsUniq  nOutgoingInternCalls  \\\n",
       "0                0.0                 0.0                   0.0   \n",
       "1                0.0                 0.0                   0.0   \n",
       "2                0.0                 0.0                   0.0   \n",
       "3                0.0                 0.0                   0.0   \n",
       "4                0.0                 0.0                   1.0   \n",
       "...              ...                 ...                   ...   \n",
       "2051           569.0               567.0                   1.0   \n",
       "2052           561.0               556.0                   3.0   \n",
       "2053             0.0                 0.0                   0.0   \n",
       "2054           568.0               567.0                   2.0   \n",
       "2055           559.0               556.0                   2.0   \n",
       "\n",
       "      nOutgoingExternFlsCalled  nOutgoingExternFlsCalledUniq  \\\n",
       "0                         36.0                          29.0   \n",
       "1                        106.0                          69.0   \n",
       "2                         69.0                          54.0   \n",
       "3                        100.0                          70.0   \n",
       "4                         94.0                          66.0   \n",
       "...                        ...                           ...   \n",
       "2051                    1049.0                        1020.0   \n",
       "2052                    1091.0                        1029.0   \n",
       "2053                      56.0                          39.0   \n",
       "2054                    1022.0                        1018.0   \n",
       "2055                    1027.0                        1018.0   \n",
       "\n",
       "      nOutgoingExternCallsUniq  IsVulnerable  \n",
       "0                         23.0             0  \n",
       "1                         50.0             0  \n",
       "2                         26.0             0  \n",
       "3                         84.0             0  \n",
       "4                         42.0             0  \n",
       "...                        ...           ...  \n",
       "2051                       3.0             0  \n",
       "2052                      28.0             0  \n",
       "2053                      30.0             0  \n",
       "2054                       2.0             0  \n",
       "2055                       4.0             0  \n",
       "\n",
       "[2056 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e285421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y value counts: \n",
      " 0    2032\n",
      "1      24\n",
      "Name: IsVulnerable, dtype: int64\n",
      "y class ratio: 1: 85\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "print(\"y value counts: \\n\", str(y.value_counts()))\n",
    "print(\"y class ratio: 1:\", str(round(y.value_counts()[0]/y.value_counts()[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92eb1294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- y train classes count: \n",
      "0    1625\n",
      "1      19\n",
      "Name: IsVulnerable, dtype: int64\n",
      "--- y train ratio: 1:86\n",
      " \n",
      "--- y test classes count: \n",
      "0    407\n",
      "1      5\n",
      "Name: IsVulnerable, dtype: int64\n",
      "--- y test ratio: 1:81\n"
     ]
    }
   ],
   "source": [
    "rs = random.randint(0, 100000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=rs)\n",
    "print(\"--- y train classes count: \\n\" + str(y_train.value_counts()))\n",
    "print(\"--- y train ratio: 1:\" + str(round(y_train.value_counts()[0] / y_train.value_counts()[1])))\n",
    "print(\" \")\n",
    "print(\"--- y test classes count: \\n\" + str(y_test.value_counts()))\n",
    "print(\"--- y test ratio: 1:\" + str(round(y_test.value_counts()[0] / y_test.value_counts()[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274c8bf8",
   "metadata": {},
   "source": [
    "# Defect Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a9eccaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file = \"defect_prediction_r3.csv\"\n",
    "write_path = f\"{os.path.dirname(os.getcwd())}/result/{write_file}\"\n",
    "with open(write_path, \"w\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    csv_writer.writerow([\"oversampling_scheme\", \"runtime\", \"learner\", \"acc\", \"prec\", \"recall\", \"fpr\", \"f1\", \"auc\", \"g_score\", \"d2h\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d192edee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = f\"{os.path.dirname(os.getcwd())}/data/imbalance_defects_prediction/7_CK_NET_PROC/input/Eclipse_JDT_Core--CK_NET_PROC.arff\"\n",
    "data = arff.loadarff(data_path)\n",
    "df = pd.DataFrame(data[0])\n",
    "df['isBug'] = df['isBug'].astype('str')\n",
    "d = {'b\\'YES\\'': 1, 'b\\'NO\\'': 0}\n",
    "df['isBug'] = df['isBug'].astype(str).map(d).fillna(df['isBug'])\n",
    "df = df.drop_duplicates()\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6540008f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wmc</th>\n",
       "      <th>dit</th>\n",
       "      <th>rfc</th>\n",
       "      <th>noc</th>\n",
       "      <th>cbo</th>\n",
       "      <th>lcom</th>\n",
       "      <th>loc</th>\n",
       "      <th>revision_num</th>\n",
       "      <th>author_num</th>\n",
       "      <th>linesadd_sum</th>\n",
       "      <th>...</th>\n",
       "      <th>InFreeClo</th>\n",
       "      <th>OutValClo</th>\n",
       "      <th>InValClo</th>\n",
       "      <th>OutRecipClo</th>\n",
       "      <th>InRecipClo</th>\n",
       "      <th>OutdwReach</th>\n",
       "      <th>IndwReach</th>\n",
       "      <th>nOutdwReach</th>\n",
       "      <th>nIndwReach</th>\n",
       "      <th>isBug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>0.953028</td>\n",
       "      <td>0.502399</td>\n",
       "      <td>0.206168</td>\n",
       "      <td>0.134612</td>\n",
       "      <td>206.300583</td>\n",
       "      <td>134.578400</td>\n",
       "      <td>0.206921</td>\n",
       "      <td>0.134983</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.503744</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.153207</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.099930</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.153561</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.955744</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.242747</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>242.734924</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.243465</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.952940</td>\n",
       "      <td>0.503016</td>\n",
       "      <td>0.199539</td>\n",
       "      <td>0.182509</td>\n",
       "      <td>199.697235</td>\n",
       "      <td>182.283066</td>\n",
       "      <td>0.200298</td>\n",
       "      <td>0.182832</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.503914</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.168100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>167.933151</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.168438</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>84.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.952831</td>\n",
       "      <td>0.501852</td>\n",
       "      <td>0.205453</td>\n",
       "      <td>0.100706</td>\n",
       "      <td>205.588043</td>\n",
       "      <td>100.808090</td>\n",
       "      <td>0.206207</td>\n",
       "      <td>0.101111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>50.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002013</td>\n",
       "      <td>0.953497</td>\n",
       "      <td>0.502353</td>\n",
       "      <td>0.248260</td>\n",
       "      <td>0.124990</td>\n",
       "      <td>248.223679</td>\n",
       "      <td>124.995102</td>\n",
       "      <td>0.248971</td>\n",
       "      <td>0.125371</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.952784</td>\n",
       "      <td>0.501867</td>\n",
       "      <td>0.200952</td>\n",
       "      <td>0.101158</td>\n",
       "      <td>201.104736</td>\n",
       "      <td>101.258087</td>\n",
       "      <td>0.201710</td>\n",
       "      <td>0.101563</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.258222</td>\n",
       "      <td>0.504385</td>\n",
       "      <td>0.065971</td>\n",
       "      <td>0.086352</td>\n",
       "      <td>65.966690</td>\n",
       "      <td>86.514275</td>\n",
       "      <td>0.066165</td>\n",
       "      <td>0.086775</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002013</td>\n",
       "      <td>0.954184</td>\n",
       "      <td>0.502125</td>\n",
       "      <td>0.279579</td>\n",
       "      <td>0.111660</td>\n",
       "      <td>279.417847</td>\n",
       "      <td>111.718796</td>\n",
       "      <td>0.280259</td>\n",
       "      <td>0.112055</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>997 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      wmc  dit    rfc  noc  cbo  lcom    loc  revision_num  author_num  \\\n",
       "0    18.0  1.0   46.0  0.0  7.0  78.0   82.0          26.0         4.0   \n",
       "1     5.0  1.0    5.0  0.0  2.0  10.0   18.0          22.0         4.0   \n",
       "2    14.0  1.0   28.0  0.0  7.0   6.0   50.0          16.0         6.0   \n",
       "3    13.0  1.0   21.0  1.0  4.0  45.0   69.0          43.0         8.0   \n",
       "4     1.0  1.0    2.0  0.0  1.0   1.0    3.0          14.0         4.0   \n",
       "..    ...  ...    ...  ...  ...   ...    ...           ...         ...   \n",
       "992  84.0  2.0  126.0  1.0  6.0  66.0  276.0           5.0         1.0   \n",
       "993  50.0  2.0   51.0  1.0  6.0  45.0  121.0           7.0         1.0   \n",
       "994  12.0  2.0   25.0  0.0  4.0  36.0   48.0           3.0         1.0   \n",
       "995  21.0  1.0   29.0  2.0  5.0  55.0   81.0           7.0         1.0   \n",
       "996  24.0  1.0   38.0  0.0  6.0   1.0  131.0          19.0         6.0   \n",
       "\n",
       "     linesadd_sum  ...  InFreeClo  OutValClo  InValClo  OutRecipClo  \\\n",
       "0           332.0  ...   0.002014   0.953028  0.502399     0.206168   \n",
       "1           192.0  ...   0.002019   0.000000  0.503744     0.001003   \n",
       "2            69.0  ...   0.001003   0.955744  0.000000     0.242747   \n",
       "3           485.0  ...   0.002016   0.952940  0.503016     0.199539   \n",
       "4            55.0  ...   0.002020   0.000000  0.503914     0.001003   \n",
       "..            ...  ...        ...        ...       ...          ...   \n",
       "992          23.0  ...   0.002011   0.952831  0.501852     0.205453   \n",
       "993           9.0  ...   0.002013   0.953497  0.502353     0.248260   \n",
       "994           2.0  ...   0.002011   0.952784  0.501867     0.200952   \n",
       "995          12.0  ...   0.002022   0.258222  0.504385     0.065971   \n",
       "996         317.0  ...   0.002013   0.954184  0.502125     0.279579   \n",
       "\n",
       "     InRecipClo  OutdwReach   IndwReach  nOutdwReach  nIndwReach  isBug  \n",
       "0      0.134612  206.300583  134.578400     0.206921    0.134983      0  \n",
       "1      0.153207    1.000000  153.099930     0.001003    0.153561      0  \n",
       "2      0.001003  242.734924    1.000000     0.243465    0.001003      0  \n",
       "3      0.182509  199.697235  182.283066     0.200298    0.182832      0  \n",
       "4      0.168100    1.000000  167.933151     0.001003    0.168438      0  \n",
       "..          ...         ...         ...          ...         ...    ...  \n",
       "992    0.100706  205.588043  100.808090     0.206207    0.101111      0  \n",
       "993    0.124990  248.223679  124.995102     0.248971    0.125371      0  \n",
       "994    0.101158  201.104736  101.258087     0.201710    0.101563      0  \n",
       "995    0.086352   65.966690   86.514275     0.066165    0.086775      0  \n",
       "996    0.111660  279.417847  111.718796     0.280259    0.112055      0  \n",
       "\n",
       "[997 rows x 82 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5de1863b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y value counts: \n",
      " 0    791\n",
      "1    206\n",
      "Name: isBug, dtype: int64\n",
      "y class ratio: 1: 4\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "print(\"y value counts: \\n\", str(y.value_counts()))\n",
    "print(\"y class ratio: 1:\", str(round(y.value_counts()[0]/y.value_counts()[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2eb2d50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- y train classes count: \n",
      "0    632\n",
      "1    165\n",
      "Name: isBug, dtype: int64\n",
      "--- y train ratio: 1:4\n",
      " \n",
      "--- y test classes count: \n",
      "0    159\n",
      "1     41\n",
      "Name: isBug, dtype: int64\n",
      "--- y test ratio: 1:4\n"
     ]
    }
   ],
   "source": [
    "rs = random.randint(0, 100000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=rs)\n",
    "print(\"--- y train classes count: \\n\" + str(y_train.value_counts()))\n",
    "print(\"--- y train ratio: 1:\" + str(round(y_train.value_counts()[0] / y_train.value_counts()[1])))\n",
    "print(\" \")\n",
    "print(\"--- y test classes count: \\n\" + str(y_test.value_counts()))\n",
    "print(\"--- y test ratio: 1:\" + str(round(y_test.value_counts()[0] / y_test.value_counts()[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2882950",
   "metadata": {},
   "source": [
    "### Normal Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a551b5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal run - without any oversampling technique\n",
    "# inputs: X_train, y_train, X_test, y_test\n",
    "\n",
    "# scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scale = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_test_scale = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_scale, y_train)\n",
    "clf_KNN.fit(X_train_scale, y_train)\n",
    "clf_LR.fit(X_train_scale, y_train)\n",
    "clf_DT.fit(X_train_scale, y_train)\n",
    "clf_RF.fit(X_train_scale, y_train)\n",
    "clf_LightGBM.fit(X_train_scale, y_train)\n",
    "clf_Adaboost.fit(X_train_scale, y_train)\n",
    "clf_GBDT.fit(X_train_scale, y_train)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test_scale)\n",
    "y_pred_KNN = clf_KNN.predict(X_test_scale)\n",
    "y_pred_LR = clf_LR.predict(X_test_scale)\n",
    "y_pred_DT = clf_DT.predict(X_test_scale)\n",
    "y_pred_RF = clf_RF.predict(X_test_scale)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test_scale)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test_scale)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef74cf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/{write_file}\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"No\", 0, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"No\", 0, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"No\", 0, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"No\", 0, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"No\", 0, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"No\", 0, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"No\", 0, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"No\", 0, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21cfd37",
   "metadata": {},
   "source": [
    "### Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7f33936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train ratio: 1:1\n"
     ]
    }
   ],
   "source": [
    "# random oversampling run - random oversampling technique\n",
    "# inputs: X_train_random, y_train_random, X_test, y_test\n",
    "\n",
    "rt, X_train_new, y_train_new = RandomOversampling(X_train=X_train, y_train=y_train)\n",
    "\n",
    "# scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scale = pd.DataFrame(scaler.fit_transform(X_train_new), columns=X_train_new.columns, index=X_train_new.index)\n",
    "X_test_scale = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(\"y train ratio: 1:\" + str(round(y_train_new.value_counts()[0] / y_train_new.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new, y_train_new)\n",
    "clf_KNN.fit(X_train_new, y_train_new)\n",
    "clf_LR.fit(X_train_new, y_train_new)\n",
    "clf_DT.fit(X_train_new, y_train_new)\n",
    "clf_RF.fit(X_train_new, y_train_new)\n",
    "clf_LightGBM.fit(X_train_new, y_train_new)\n",
    "clf_Adaboost.fit(X_train_new, y_train_new)\n",
    "clf_GBDT.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3d0c717",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/{write_file}\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"Random\", rt, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"Random\", rt, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"Random\", rt, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"Random\", rt, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"Random\", rt, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"Random\", rt, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"Random\", rt, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"Random\", rt, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281db9c2",
   "metadata": {},
   "source": [
    "### ADASYN Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfbda71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train ratio: 1:1\n"
     ]
    }
   ],
   "source": [
    "# ADASYN oversampling run - ADASYN oversampling technique\n",
    "# inputs: X_train_random, y_train_random, X_test, y_test\n",
    "\n",
    "rt, X_train_new, y_train_new = ADASYNOversampling(X_train=X_train, y_train=y_train)\n",
    "\n",
    "# scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scale = pd.DataFrame(scaler.fit_transform(X_train_new), columns=X_train_new.columns, index=X_train_new.index)\n",
    "X_test_scale = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(\"y train ratio: 1:\" + str(round(y_train_new.value_counts()[0] / y_train_new.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new, y_train_new)\n",
    "clf_KNN.fit(X_train_new, y_train_new)\n",
    "clf_LR.fit(X_train_new, y_train_new)\n",
    "clf_DT.fit(X_train_new, y_train_new)\n",
    "clf_RF.fit(X_train_new, y_train_new)\n",
    "clf_LightGBM.fit(X_train_new, y_train_new)\n",
    "clf_Adaboost.fit(X_train_new, y_train_new)\n",
    "clf_GBDT.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69242434",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/{write_file}\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"ADASYN\", rt, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"ADASYN\", rt, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"ADASYN\", rt, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"ADASYN\", rt, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"ADASYN\", rt, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"ADASYN\", rt, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"ADASYN\", rt, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"ADASYN\", rt, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b58555c",
   "metadata": {},
   "source": [
    "### BorderlineSMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be4efbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train ratio: 1:1\n"
     ]
    }
   ],
   "source": [
    "# BorderlineSMOTE oversampling run - BorderlineSMOTE oversampling technique\n",
    "# inputs: X_train_random, y_train_random, X_test, y_test\n",
    "\n",
    "rt, X_train_new, y_train_new = BorderlineSMOTEOversampling(X_train=X_train, y_train=y_train)\n",
    "\n",
    "# scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scale = pd.DataFrame(scaler.fit_transform(X_train_new), columns=X_train_new.columns, index=X_train_new.index)\n",
    "X_test_scale = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(\"y train ratio: 1:\" + str(round(y_train_new.value_counts()[0] / y_train_new.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new, y_train_new)\n",
    "clf_KNN.fit(X_train_new, y_train_new)\n",
    "clf_LR.fit(X_train_new, y_train_new)\n",
    "clf_DT.fit(X_train_new, y_train_new)\n",
    "clf_RF.fit(X_train_new, y_train_new)\n",
    "clf_LightGBM.fit(X_train_new, y_train_new)\n",
    "clf_Adaboost.fit(X_train_new, y_train_new)\n",
    "clf_GBDT.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4eb176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/{write_file}\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"BorderlineSMOTE\", rt, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"BorderlineSMOTE\", rt, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"BorderlineSMOTE\", rt, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"BorderlineSMOTE\", rt, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"BorderlineSMOTE\", rt, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"BorderlineSMOTE\", rt, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"BorderlineSMOTE\", rt, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"BorderlineSMOTE\", rt, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10af448",
   "metadata": {},
   "source": [
    "### SMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f35552fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train ratio: 1:1\n"
     ]
    }
   ],
   "source": [
    "# SMOTE oversampling run - SMOTE oversampling technique\n",
    "# inputs: X_train_random, y_train_random, X_test, y_test\n",
    "\n",
    "rt, X_train_new, y_train_new = SMOTEOversampling(X_train=X_train, y_train=y_train)\n",
    "\n",
    "# scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scale = pd.DataFrame(scaler.fit_transform(X_train_new), columns=X_train_new.columns, index=X_train_new.index)\n",
    "X_test_scale = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(\"y train ratio: 1:\" + str(round(y_train_new.value_counts()[0] / y_train_new.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new, y_train_new)\n",
    "clf_KNN.fit(X_train_new, y_train_new)\n",
    "clf_LR.fit(X_train_new, y_train_new)\n",
    "clf_DT.fit(X_train_new, y_train_new)\n",
    "clf_RF.fit(X_train_new, y_train_new)\n",
    "clf_LightGBM.fit(X_train_new, y_train_new)\n",
    "clf_Adaboost.fit(X_train_new, y_train_new)\n",
    "clf_GBDT.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "861996c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/{write_file}\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"SMOTE\", rt, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"SMOTE\", rt, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"SMOTE\", rt, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"SMOTE\", rt, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"SMOTE\", rt, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"SMOTE\", rt, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"SMOTE\", rt, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"SMOTE\", rt, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030725b0",
   "metadata": {},
   "source": [
    "### SVMSMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a8f0bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train ratio: 1:1\n"
     ]
    }
   ],
   "source": [
    "# SVMSMOTE oversampling run - SVMSMOTE oversampling technique\n",
    "# inputs: X_train_random, y_train_random, X_test, y_test\n",
    "\n",
    "rt, X_train_new, y_train_new = SVMSMOTEOversampling(X_train=X_train, y_train=y_train)\n",
    "\n",
    "# scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scale = pd.DataFrame(scaler.fit_transform(X_train_new), columns=X_train_new.columns, index=X_train_new.index)\n",
    "X_test_scale = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(\"y train ratio: 1:\" + str(round(y_train_new.value_counts()[0] / y_train_new.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new, y_train_new)\n",
    "clf_KNN.fit(X_train_new, y_train_new)\n",
    "clf_LR.fit(X_train_new, y_train_new)\n",
    "clf_DT.fit(X_train_new, y_train_new)\n",
    "clf_RF.fit(X_train_new, y_train_new)\n",
    "clf_LightGBM.fit(X_train_new, y_train_new)\n",
    "clf_Adaboost.fit(X_train_new, y_train_new)\n",
    "clf_GBDT.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38e7465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/{write_file}\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"SVMSMOTE\", rt, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"SVMSMOTE\", rt, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"SVMSMOTE\", rt, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"SVMSMOTE\", rt, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"SVMSMOTE\", rt, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"SVMSMOTE\", rt, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"SVMSMOTE\", rt, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"SVMSMOTE\", rt, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce4dca6",
   "metadata": {},
   "source": [
    "### SMOTUNED Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45eadca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train ratio of SVM: 1:1\n",
      "y train ratio of KNN: 1:1\n",
      "y train ratio of LR: 1:1\n",
      "y train ratio of DT: 1:1\n",
      "y train ratio of RF: 1:1\n",
      "y train ratio of LightGBM: 1:1\n",
      "y train ratio of Adaboost: 1:1\n",
      "y train ratio of GBDT: 1:1\n"
     ]
    }
   ],
   "source": [
    "# SMOTUNED oversampling run - SMOTUNED oversampling technique\n",
    "# inputs: X_train_random, y_train_random, X_test, y_test\n",
    "\n",
    "rt_SVM, X_train_new_SVM, y_train_new_SVM = SMOTUNEDOversampling(X_train=X_train, X_test=X_test, \n",
    "                                                                y_train=y_train, y_test=y_test, model=\"SVM\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scale = pd.DataFrame(scaler.fit_transform(X_train_new_SVM), columns=X_train_new_SVM.columns)\n",
    "X_test_scale = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "print(\"y train ratio of SVM: 1:\" + str(round(y_train_new_SVM.value_counts()[0] / y_train_new_SVM.value_counts()[1])))\n",
    "\n",
    "rt_KNN, X_train_new_KNN, y_train_new_KNN = SMOTUNEDOversampling(X_train=X_train, X_test=X_test, \n",
    "                                                                y_train=y_train, y_test=y_test, model=\"KNN\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scale = pd.DataFrame(scaler.fit_transform(X_train_new_KNN), columns=X_train_new_KNN.columns)\n",
    "X_test_scale = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "print(\"y train ratio of KNN: 1:\" + str(round(y_train_new_KNN.value_counts()[0] / y_train_new_KNN.value_counts()[1])))\n",
    "\n",
    "rt_LR, X_train_new_LR, y_train_new_LR = SMOTUNEDOversampling(X_train=X_train, X_test=X_test, \n",
    "                                                             y_train=y_train, y_test=y_test, model=\"LR\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scale = pd.DataFrame(scaler.fit_transform(X_train_new_LR), columns=X_train_new_LR.columns)\n",
    "X_test_scale = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "print(\"y train ratio of LR: 1:\" + str(round(y_train_new_LR.value_counts()[0] / y_train_new_LR.value_counts()[1])))\n",
    "\n",
    "rt_DT, X_train_new_DT, y_train_new_DT = SMOTUNEDOversampling(X_train=X_train, X_test=X_test, \n",
    "                                                             y_train=y_train, y_test=y_test, model=\"DT\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scale = pd.DataFrame(scaler.fit_transform(X_train_new_DT), columns=X_train_new_DT.columns)\n",
    "X_test_scale = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "print(\"y train ratio of DT: 1:\" + str(round(y_train_new_DT.value_counts()[0] / y_train_new_DT.value_counts()[1])))\n",
    "\n",
    "rt_RF, X_train_new_RF, y_train_new_RF = SMOTUNEDOversampling(X_train=X_train, X_test=X_test, \n",
    "                                                             y_train=y_train, y_test=y_test, model=\"RF\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scale = pd.DataFrame(scaler.fit_transform(X_train_new_RF), columns=X_train_new_RF.columns)\n",
    "X_test_scale = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "print(\"y train ratio of RF: 1:\" + str(round(y_train_new_RF.value_counts()[0] / y_train_new_RF.value_counts()[1])))\n",
    "\n",
    "rt_LightGBM, X_train_new_LightGBM, y_train_new_LightGBM = SMOTUNEDOversampling(X_train=X_train, X_test=X_test, \n",
    "                                                                               y_train=y_train, y_test=y_test, model=\"LightGBM\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scale = pd.DataFrame(scaler.fit_transform(X_train_new_LightGBM), columns=X_train_new_LightGBM.columns)\n",
    "X_test_scale = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "print(\"y train ratio of LightGBM: 1:\" + str(round(y_train_new_LightGBM.value_counts()[0] / y_train_new_LightGBM.value_counts()[1])))\n",
    "\n",
    "rt_Adaboost, X_train_new_Adaboost, y_train_new_Adaboost = SMOTUNEDOversampling(X_train=X_train, X_test=X_test, \n",
    "                                                                               y_train=y_train, y_test=y_test, model=\"Adaboost\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scale = pd.DataFrame(scaler.fit_transform(X_train_new_Adaboost), columns=X_train_new_Adaboost.columns)\n",
    "X_test_scale = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "print(\"y train ratio of Adaboost: 1:\" + str(round(y_train_new_Adaboost.value_counts()[0] / y_train_new_Adaboost.value_counts()[1])))\n",
    "\n",
    "rt_GBDT, X_train_new_GBDT, y_train_new_GBDT = SMOTUNEDOversampling(X_train=X_train, X_test=X_test, \n",
    "                                                                   y_train=y_train, y_test=y_test, model=\"GBDT\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scale = pd.DataFrame(scaler.fit_transform(X_train_new_GBDT), columns=X_train_new_GBDT.columns)\n",
    "X_test_scale = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "print(\"y train ratio of GBDT: 1:\" + str(round(y_train_new_GBDT.value_counts()[0] / y_train_new_GBDT.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new_SVM, y_train_new_SVM)\n",
    "clf_KNN.fit(X_train_new_KNN, y_train_new_KNN)\n",
    "clf_LR.fit(X_train_new_LR, y_train_new_LR)\n",
    "clf_DT.fit(X_train_new_DT, y_train_new_DT)\n",
    "clf_RF.fit(X_train_new_RF, y_train_new_RF)\n",
    "clf_LightGBM.fit(X_train_new_LightGBM, y_train_new_LightGBM)\n",
    "clf_Adaboost.fit(X_train_new_Adaboost, y_train_new_Adaboost)\n",
    "clf_GBDT.fit(X_train_new_GBDT, y_train_new_GBDT)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdd1a2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/{write_file}\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"SMOTUNED\", rt_SVM, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"SMOTUNED\", rt_KNN, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"SMOTUNED\", rt_LR, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"SMOTUNED\", rt_DT, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"SMOTUNED\", rt_RF, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"SMOTUNED\", rt_LightGBM, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"SMOTUNED\", rt_Adaboost, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"SMOTUNED\", rt_GBDT, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d4ab51",
   "metadata": {},
   "source": [
    "### DAZZLE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7eb04177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                           | 0/100 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-19 12:50:31.798203: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-19 12:50:31.798478: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 100/100 [00:59<00:00,  1.68trial/s, best loss: -0.8443986178332092]\n",
      "Best Hyperparameters: {'batch_size': 16, 'discriminator_activation_fn': <function leaky_relu at 0x7f33e8934160>, 'discriminator_layer_normalization': True, 'discriminator_lr': 0.0009917984440465412, 'discriminator_optimizer': <class 'keras.src.optimizers.sgd.SGD'>, 'epochs': 15, 'generator_activation_fn': <function leaky_relu at 0x7f33e8934160>, 'generator_layer_normalization': False, 'generator_lr': 0.0035633076617442015, 'generator_optimizer': <class 'keras.src.optimizers.adamax.Adamax'>}\n",
      "Best G-Measure: 0.8443986178332092\n",
      "25/25 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train ratio: 1:1\n"
     ]
    }
   ],
   "source": [
    "# DAZZLE oversampling run - DAZZLE oversampling technique\n",
    "# inputs: X_train_random, y_train_random, X_test, y_test\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_GAN = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "rt, X_train_new, y_train_new = DAZZLEOversampling(X_train=X_train_GAN, y_train=y_train)\n",
    "\n",
    "# scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scale = pd.DataFrame(scaler.fit_transform(X_train_new), columns=X_train_new.columns, index=X_train_new.index)\n",
    "X_test_scale = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(\"y train ratio: 1:\" + str(round(y_train_new.value_counts()[0] / y_train_new.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new, y_train_new)\n",
    "clf_KNN.fit(X_train_new, y_train_new)\n",
    "clf_LR.fit(X_train_new, y_train_new)\n",
    "clf_DT.fit(X_train_new, y_train_new)\n",
    "clf_RF.fit(X_train_new, y_train_new)\n",
    "clf_LightGBM.fit(X_train_new, y_train_new)\n",
    "clf_Adaboost.fit(X_train_new, y_train_new)\n",
    "clf_GBDT.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23be0d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/{write_file}\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"DAZZLE\", rt, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"DAZZLE\", rt, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"DAZZLE\", rt, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"DAZZLE\", rt, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"DAZZLE\", rt, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"DAZZLE\", rt, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"DAZZLE\", rt, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"DAZZLE\", rt, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018ee189",
   "metadata": {},
   "source": [
    "### WGAN Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "889973b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX CLASS 632\n",
      "CLASS ID 1\n",
      "Epoch 1/150 completed. Gen loss: -0.01348569430410862. Desc loss_real: 0.019305530935525894. Desc loss_fake: 0.01348569430410862\n",
      "Epoch 51/150 completed. Gen loss: -0.0016907525714486837. Desc loss_real: 0.011242654174566269. Desc loss_fake: 0.0016907525714486837\n",
      "Epoch 101/150 completed. Gen loss: -0.0033969709184020758. Desc loss_real: 0.014724577777087688. Desc loss_fake: 0.0033969709184020758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/e/Research/SyntheticData/src/data_imbalance_src/Imbalance_Farou2022/data_generation.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data = new_data.append(synthetic_data)\n",
      "/mnt/e/Research/SyntheticData/src/data_imbalance_src/Imbalance_Farou2022/data_generation.py:133: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  X_sample = X_sample.append(X_train)\n",
      "/mnt/e/Research/SyntheticData/src/data_imbalance_src/Imbalance_Farou2022/data_generation.py:135: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  X_sample = X_sample.drop(tar, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train ratio: 1:1\n"
     ]
    }
   ],
   "source": [
    "# WGAN oversampling run - WGAN oversampling technique\n",
    "# inputs: X_train_random, y_train_random, X_test, y_test\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_GAN = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "rt, X_train_new, y_train_new = GANOversampling(X_train=X_train_GAN, y_train=y_train)\n",
    "\n",
    "# scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scale = pd.DataFrame(scaler.fit_transform(X_train_new), columns=X_train_new.columns, index=X_train_new.index)\n",
    "X_test_scale = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(\"y train ratio: 1:\" + str(round(y_train_new.value_counts()[0] / y_train_new.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new, y_train_new)\n",
    "clf_KNN.fit(X_train_new, y_train_new)\n",
    "clf_LR.fit(X_train_new, y_train_new)\n",
    "clf_DT.fit(X_train_new, y_train_new)\n",
    "clf_RF.fit(X_train_new, y_train_new)\n",
    "clf_LightGBM.fit(X_train_new, y_train_new)\n",
    "clf_Adaboost.fit(X_train_new, y_train_new)\n",
    "clf_GBDT.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0a87e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/{write_file}\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"WGAN\", rt, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"WGAN\", rt, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"WGAN\", rt, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"WGAN\", rt, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"WGAN\", rt, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"WGAN\", rt, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"WGAN\", rt, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"WGAN\", rt, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477e3384",
   "metadata": {},
   "source": [
    "### Random Projection Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9875370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train ratio: 1:1\n"
     ]
    }
   ],
   "source": [
    "# Random projection oversampling run - Random projection oversampling technique\n",
    "# inputs: X_train_random, y_train_random, X_test, y_test\n",
    "\n",
    "rt, X_train_new, y_train_new = RandomProjectionOversampling(X_train=X_train, y_train=y_train)\n",
    "\n",
    "# scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scale = pd.DataFrame(scaler.fit_transform(X_train_new), columns=X_train_new.columns, index=X_train_new.index)\n",
    "X_test_scale = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(\"y train ratio: 1:\" + str(round(y_train_new.value_counts()[0] / y_train_new.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new, y_train_new)\n",
    "clf_KNN.fit(X_train_new, y_train_new)\n",
    "clf_LR.fit(X_train_new, y_train_new)\n",
    "clf_DT.fit(X_train_new, y_train_new)\n",
    "clf_RF.fit(X_train_new, y_train_new)\n",
    "clf_LightGBM.fit(X_train_new, y_train_new)\n",
    "clf_Adaboost.fit(X_train_new, y_train_new)\n",
    "clf_GBDT.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "398fad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/{write_file}\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"RP\", rt, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"RP\", rt, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"RP\", rt, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"RP\", rt, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"RP\", rt, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"RP\", rt, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"RP\", rt, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"RP\", rt, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6625ff",
   "metadata": {},
   "source": [
    "### Diveplane Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "288bec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diveplane.utilities import infer_feature_attributes\n",
    "from diveplane.geminai import Geminai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7908f824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/diveplane/geminai/base.py:376: UserWarning: The value of the parameter `generate_new_cases` is set as 'no' and not 'always', which means it is possible that some cases that are very similar to the original data may be returned. To prevent this from happening, please set generate_new_cases to 'always'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tar = y_train.name\n",
    "conditions = [{tar: 1},\n",
    "              {tar: 0}] * (int(X_train.shape[0] / 2))\n",
    "\n",
    "X_train[tar] = y_train\n",
    "# partial_features = {\"CLLC\": {'type': \"continuous\"}}\n",
    "features = infer_feature_attributes(X_train)\n",
    "for f_name, f_value in features.items():\n",
    "    if f_value[\"type\"] == \"nominal\":\n",
    "        f_value[\"non_sensitive\"] = True\n",
    "\n",
    "start_time = time.time()\n",
    "g = Geminai()\n",
    "g.train(X_train, features=features)\n",
    "\n",
    "gen_df = g.synthesize_cases(\n",
    "    n_samples=len(conditions),\n",
    "    case_context_values_maps=conditions,\n",
    "    generate_new_cases=\"no\"\n",
    ")\n",
    "\n",
    "rt = time.time() - start_time\n",
    "\n",
    "X_train = X_train.iloc[:, :-1]\n",
    "X_train_new = gen_df.iloc[:, :-1]\n",
    "y_train_new = gen_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "daf865a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train ratio: 1:1\n"
     ]
    }
   ],
   "source": [
    "# scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scale = pd.DataFrame(scaler.fit_transform(X_train_new), columns=X_train_new.columns, index=X_train_new.index)\n",
    "X_test_scale = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(\"y train ratio: 1:\" + str(round(y_train_new.value_counts()[0] / y_train_new.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new, y_train_new)\n",
    "clf_KNN.fit(X_train_new, y_train_new)\n",
    "clf_LR.fit(X_train_new, y_train_new)\n",
    "clf_DT.fit(X_train_new, y_train_new)\n",
    "clf_RF.fit(X_train_new, y_train_new)\n",
    "clf_LightGBM.fit(X_train_new, y_train_new)\n",
    "clf_Adaboost.fit(X_train_new, y_train_new)\n",
    "clf_GBDT.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "82a127b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'write_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mgetcwd())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/result/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwrite_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      2\u001b[0m     csv_writer \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mwriter(f)\n\u001b[1;32m      4\u001b[0m     csv_writer\u001b[38;5;241m.\u001b[39mwriterow([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDiveplane\u001b[39m\u001b[38;5;124m\"\u001b[39m, rt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVM\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m evaluate_result(y_pred_SVM, y_test))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'write_file' is not defined"
     ]
    }
   ],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/{write_file}\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"Diveplane\", rt, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"Diveplane\", rt, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"Diveplane\", rt, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"Diveplane\", rt, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"Diveplane\", rt, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"Diveplane\", rt, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"Diveplane\", rt, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"Diveplane\", rt, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "69d0cd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/diveplane/geminai/base.py:376: UserWarning: The value of the parameter `generate_new_cases` is set as 'no' and not 'always', which means it is possible that some cases that are very similar to the original data may be returned. To prevent this from happening, please set generate_new_cases to 'always'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tar = y_train.name\n",
    "n_cases_diff = y_train.value_counts()[0] - y_train.value_counts()[1]\n",
    "conditions = [{tar: 1}] * n_cases_diff\n",
    "\n",
    "X_train_diveplane = X_train.copy()\n",
    "y_train_diveplane = y_train.copy()\n",
    "X_train_diveplane[tar] = y_train_diveplane\n",
    "\n",
    "features = infer_feature_attributes(X_train_diveplane)\n",
    "for f_name, f_value in features.items():\n",
    "    if f_value[\"type\"] == \"nominal\":\n",
    "        f_value[\"non_sensitive\"] = True\n",
    "\n",
    "start_time = time.time()\n",
    "g = Geminai()\n",
    "g.train(X_train_diveplane, features=features)\n",
    "\n",
    "gen_df = g.synthesize_cases(\n",
    "    n_samples=len(conditions),\n",
    "    case_context_values_maps=conditions,\n",
    "    desired_conviction=5,\n",
    "    generate_new_cases=\"no\"\n",
    ")\n",
    "\n",
    "rt = time.time() - start_time\n",
    "\n",
    "X_train_new = pd.concat([X_train_diveplane, gen_df], ignore_index=True, axis=0)\n",
    "y_train_new = X_train_new.iloc[:, -1]\n",
    "X_train_new = X_train_new.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e8e567b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4293"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_new.value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "56ca022d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4293"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_new.value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bf064700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_new.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18849a01",
   "metadata": {},
   "source": [
    "### DS Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4f2eb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataSynthesizer.DataDescriber import DataDescriber\n",
    "from DataSynthesizer.DataGenerator import DataGenerator\n",
    "from DataSynthesizer.ModelInspector import ModelInspector\n",
    "from DataSynthesizer.lib.utils import read_json_file, display_bayesian_network\n",
    "mode = \"independent_attribute_mode\"\n",
    "\n",
    "col = X_train.columns\n",
    "tar = y_train.name\n",
    "X_train[tar] = y_train\n",
    "write_df = X_train[X_train[tar] == 1]\n",
    "write_df = write_df.iloc[:, :-1]\n",
    "write_df.to_csv(f\"{os.path.dirname(os.getcwd())}/extra/js_vuln_pos_df.csv\", index=False)\n",
    "X_train = X_train.iloc[:, :-1]\n",
    "\n",
    "threshold = 20\n",
    "num_tuples_to_generate = int(y_train.value_counts()[0] - y_train.value_counts()[1])\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "description_file = f\"{os.path.dirname(os.getcwd())}/extra/js_vuln.json\"\n",
    "describer = DataDescriber(category_threshold=threshold)\n",
    "describer.describe_dataset_in_independent_attribute_mode(\n",
    "    dataset_file=f\"{os.path.dirname(os.getcwd())}/extra/js_vuln_pos_df.csv\"\n",
    ")\n",
    "describer.save_dataset_description_to_file(description_file)\n",
    "\n",
    "generator = DataGenerator()\n",
    "generator.generate_dataset_in_independent_mode(num_tuples_to_generate, description_file)\n",
    "generator.save_synthetic_data(f\"{os.path.dirname(os.getcwd())}/extra/js_vuln_syn_df.csv\")\n",
    "\n",
    "rt = time.time() - start_time\n",
    "\n",
    "X_train_new = pd.read_csv(f\"{os.path.dirname(os.getcwd())}/extra/js_vuln_syn_df.csv\").to_numpy()\n",
    "y_train_new = np.ones(num_tuples_to_generate)\n",
    "X_train_new = pd.DataFrame(np.vstack((X_train.to_numpy(), X_train_new)), columns=col)\n",
    "y_train_new = pd.Series(np.hstack((y_train.to_numpy(), y_train_new)), name=tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97d2dcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train ratio: 1:1\n"
     ]
    }
   ],
   "source": [
    "# scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scale = pd.DataFrame(scaler.fit_transform(X_train_new), columns=X_train_new.columns, index=X_train_new.index)\n",
    "X_test_scale = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(\"y train ratio: 1:\" + str(round(y_train_new.value_counts()[0] / y_train_new.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new, y_train_new)\n",
    "clf_KNN.fit(X_train_new, y_train_new)\n",
    "clf_LR.fit(X_train_new, y_train_new)\n",
    "clf_DT.fit(X_train_new, y_train_new)\n",
    "clf_RF.fit(X_train_new, y_train_new)\n",
    "clf_LightGBM.fit(X_train_new, y_train_new)\n",
    "clf_Adaboost.fit(X_train_new, y_train_new)\n",
    "clf_GBDT.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "109e7de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/{write_file}\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"DS\", rt, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"DS\", rt, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"DS\", rt, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"DS\", rt, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"DS\", rt, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"DS\", rt, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"DS\", rt, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"DS\", rt, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b40c3d8",
   "metadata": {},
   "source": [
    "### SDV Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25c763b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.metadata import SingleTableMetadata\n",
    "from sdv.lite import SingleTablePreset\n",
    "from sdv.single_table import CTGANSynthesizer\n",
    "from sdv.single_table import GaussianCopulaSynthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00cba1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = X_train.columns\n",
    "tar = y_train.name\n",
    "num_tuples_to_generate = int(y_train.value_counts()[0] - y_train.value_counts()[1])\n",
    "X_train[tar] = y_train\n",
    "pos_df = X_train[X_train[tar] == 1]\n",
    "pos_df = pos_df.iloc[:, :-1]\n",
    "X_train = X_train.iloc[:, :-1]\n",
    "\n",
    "metadata = SingleTableMetadata()\n",
    "metadata.detect_from_dataframe(data=pos_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea2ce021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train ratio: 1:1\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "syn1 = SingleTablePreset(metadata, name=\"FAST_ML\")\n",
    "syn1.fit(data=pos_df)\n",
    "X_train_new = syn1.sample(num_rows=num_tuples_to_generate).to_numpy()\n",
    "\n",
    "rt = time.time() - start_time\n",
    "\n",
    "X_train_new = pd.DataFrame(np.vstack((X_train.to_numpy(), X_train_new)), columns=col)\n",
    "y_train_new = np.ones(num_tuples_to_generate)\n",
    "y_train_new = pd.Series(np.hstack((y_train.to_numpy(), y_train_new)), name=tar)\n",
    "\n",
    "# scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scale = pd.DataFrame(scaler.fit_transform(X_train_new), columns=X_train_new.columns, index=X_train_new.index)\n",
    "X_test_scale = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(\"y train ratio: 1:\" + str(round(y_train_new.value_counts()[0] / y_train_new.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new, y_train_new)\n",
    "clf_KNN.fit(X_train_new, y_train_new)\n",
    "clf_LR.fit(X_train_new, y_train_new)\n",
    "clf_DT.fit(X_train_new, y_train_new)\n",
    "clf_RF.fit(X_train_new, y_train_new)\n",
    "clf_LightGBM.fit(X_train_new, y_train_new)\n",
    "clf_Adaboost.fit(X_train_new, y_train_new)\n",
    "clf_GBDT.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b99674a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/{write_file}\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"SDV_FASTML\", rt, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"SDV_FASTML\", rt, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"SDV_FASTML\", rt, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"SDV_FASTML\", rt, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"SDV_FASTML\", rt, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"SDV_FASTML\", rt, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"SDV_FASTML\", rt, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"SDV_FASTML\", rt, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3d41d497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train ratio: 1:1\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "syn2 = GaussianCopulaSynthesizer(metadata)\n",
    "syn2.fit(data=pos_df)\n",
    "X_train_new = syn2.sample(num_rows=num_tuples_to_generate).to_numpy()\n",
    "\n",
    "rt = time.time() - start_time\n",
    "\n",
    "X_train_new = pd.DataFrame(np.vstack((X_train.to_numpy(), X_train_new)), columns=col)\n",
    "y_train_new = np.ones(num_tuples_to_generate)\n",
    "y_train_new = pd.Series(np.hstack((y_train.to_numpy(), y_train_new)), name=tar)\n",
    "\n",
    "# scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scale = pd.DataFrame(scaler.fit_transform(X_train_new), columns=X_train_new.columns, index=X_train_new.index)\n",
    "X_test_scale = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(\"y train ratio: 1:\" + str(round(y_train_new.value_counts()[0] / y_train_new.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new, y_train_new)\n",
    "clf_KNN.fit(X_train_new, y_train_new)\n",
    "clf_LR.fit(X_train_new, y_train_new)\n",
    "clf_DT.fit(X_train_new, y_train_new)\n",
    "clf_RF.fit(X_train_new, y_train_new)\n",
    "clf_LightGBM.fit(X_train_new, y_train_new)\n",
    "clf_Adaboost.fit(X_train_new, y_train_new)\n",
    "clf_GBDT.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3003110",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/{write_file}\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"SDV_GC\", rt, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"SDV_GC\", rt, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"SDV_GC\", rt, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"SDV_GC\", rt, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"SDV_GC\", rt, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"SDV_GC\", rt, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"SDV_GC\", rt, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"SDV_GC\", rt, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2fe59698",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train ratio: 1:1\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "syn3 = CTGANSynthesizer(metadata)\n",
    "syn3.fit(data=pos_df)\n",
    "X_train_new = syn3.sample(num_rows=num_tuples_to_generate).to_numpy()\n",
    "\n",
    "rt = time.time() - start_time\n",
    "\n",
    "X_train_new = pd.DataFrame(np.vstack((X_train.to_numpy(), X_train_new)), columns=col)\n",
    "y_train_new = np.ones(num_tuples_to_generate)\n",
    "y_train_new = pd.Series(np.hstack((y_train.to_numpy(), y_train_new)), name=tar)\n",
    "\n",
    "# scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scale = pd.DataFrame(scaler.fit_transform(X_train_new), columns=X_train_new.columns, index=X_train_new.index)\n",
    "X_test_scale = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(\"y train ratio: 1:\" + str(round(y_train_new.value_counts()[0] / y_train_new.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new, y_train_new)\n",
    "clf_KNN.fit(X_train_new, y_train_new)\n",
    "clf_LR.fit(X_train_new, y_train_new)\n",
    "clf_DT.fit(X_train_new, y_train_new)\n",
    "clf_RF.fit(X_train_new, y_train_new)\n",
    "clf_LightGBM.fit(X_train_new, y_train_new)\n",
    "clf_Adaboost.fit(X_train_new, y_train_new)\n",
    "clf_GBDT.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "91df5d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/{write_file}\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"SDV_GAN\", rt, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"SDV_GAN\", rt, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"SDV_GAN\", rt, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"SDV_GAN\", rt, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"SDV_GAN\", rt, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"SDV_GAN\", rt, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"SDV_GAN\", rt, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"SDV_GAN\", rt, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a3af65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbf7def",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
