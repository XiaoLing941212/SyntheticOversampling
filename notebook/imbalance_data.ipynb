{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a136cdca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-07 12:54:00.993417: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-07 12:54:00.995099: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-07 12:54:01.029347: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-07 12:54:01.030276: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-07 12:54:01.561771: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sys.path.insert(0, f\"{os.path.dirname(os.getcwd())}/src\")\n",
    "from utils import evaluate_result\n",
    "from data_imbalance_src.smote_oversampling import RandomOversampling, ADASYNOversampling, BorderlineSMOTEOversampling, SMOTEOversampling, SVMSMOTEOversampling\n",
    "from data_imbalance_src.smote_oversampling import SMOTUNEDOversampling\n",
    "from data_imbalance_src.dazzle import DAZZLEOversampling\n",
    "from data_imbalance_src.Imbalance_Farou2022.data_generation import GANOversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f64bdbe",
   "metadata": {},
   "source": [
    "# JavaScript_Vulnerability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cc52f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_path = f\"{os.path.dirname(os.getcwd())}/result/JS_Vuln_res.csv\"\n",
    "with open(write_path, \"w\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    csv_writer.writerow([\"oversampling_scheme\", \"runtime\", \"learner\", \"acc\", \"prec\", \"recall\", \"fpr\", \"f1\", \"auc\", \"g_score\", \"d2h\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "734aa791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JSVulnerabilityDataSet-1.0.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = f\"{os.path.dirname(os.getcwd())}/data/JavaScript_Vulnerability/\"\n",
    "datafiles = [f for f in os.listdir(data_path) if f.endswith(\"csv\")]\n",
    "datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d38a3977",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{data_path}/{datafiles[0]}\")\n",
    "drop_columns = [\"name\", \"longname\", \"path\", \"full_repo_path\", \"line\", \"column\", \"endline\", \"endcolumn\"]\n",
    "df = df.drop(drop_columns, axis=1)\n",
    "df = df.drop_duplicates()\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae96fc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y value counts: \n",
      " 0    5367\n",
      "1     904\n",
      "Name: Vuln, dtype: int64\n",
      "y class ratio: 1: 6\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "print(\"y value counts: \\n\", str(y.value_counts()))\n",
    "print(\"y class ratio: 1:\", str(round(y.value_counts()[0]/y.value_counts()[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87e8b634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- y train classes count: \n",
      "0    4293\n",
      "1     723\n",
      "Name: Vuln, dtype: int64\n",
      "--- y train ratio: 1:6\n",
      " \n",
      "--- y test classes count: \n",
      "0    1074\n",
      "1     181\n",
      "Name: Vuln, dtype: int64\n",
      "--- y test ratio: 1:6\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scale = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X_scale, columns=X.columns, index=X.index)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "print(\"--- y train classes count: \\n\" + str(y_train.value_counts()))\n",
    "print(\"--- y train ratio: 1:\" + str(round(y_train.value_counts()[0] / y_train.value_counts()[1])))\n",
    "print(\" \")\n",
    "print(\"--- y test classes count: \\n\" + str(y_test.value_counts()))\n",
    "print(\"--- y test ratio: 1:\" + str(round(y_test.value_counts()[0] / y_test.value_counts()[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47da8dd",
   "metadata": {},
   "source": [
    "### Normal Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c00e1180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal run - without any oversampling technique\n",
    "# inputs: X_train, y_train, X_test, y_test\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train, y_train)\n",
    "clf_KNN.fit(X_train, y_train)\n",
    "clf_LR.fit(X_train, y_train)\n",
    "clf_DT.fit(X_train, y_train)\n",
    "clf_RF.fit(X_train, y_train)\n",
    "clf_LightGBM.fit(X_train, y_train)\n",
    "clf_Adaboost.fit(X_train, y_train)\n",
    "clf_GBDT.fit(X_train, y_train)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb26b43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/JS_Vuln_res.csv\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"No\", 0, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"No\", 0, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"No\", 0, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"No\", 0, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"No\", 0, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"No\", 0, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"No\", 0, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"No\", 0, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8531e6",
   "metadata": {},
   "source": [
    "### Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f172180c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train ratio: 1:1\n"
     ]
    }
   ],
   "source": [
    "# random oversampling run - random oversampling technique\n",
    "# inputs: X_train_random, y_train_random, X_test, y_test\n",
    "\n",
    "rt, X_train_new, y_train_new = RandomOversampling(X_train=X_train, y_train=y_train)\n",
    "\n",
    "print(\"y train ratio: 1:\" + str(round(y_train_new.value_counts()[0] / y_train_new.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new, y_train_new)\n",
    "clf_KNN.fit(X_train_new, y_train_new)\n",
    "clf_LR.fit(X_train_new, y_train_new)\n",
    "clf_DT.fit(X_train_new, y_train_new)\n",
    "clf_RF.fit(X_train_new, y_train_new)\n",
    "clf_LightGBM.fit(X_train_new, y_train_new)\n",
    "clf_Adaboost.fit(X_train_new, y_train_new)\n",
    "clf_GBDT.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f2329dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/JS_Vuln_res.csv\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"Random\", rt, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"Random\", rt, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"Random\", rt, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"Random\", rt, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"Random\", rt, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"Random\", rt, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"Random\", rt, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"Random\", rt, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c174923",
   "metadata": {},
   "source": [
    "### ADASYN Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0537e185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train ratio: 1:1\n"
     ]
    }
   ],
   "source": [
    "# ADASYN oversampling run - ADASYN oversampling technique\n",
    "# inputs: X_train_random, y_train_random, X_test, y_test\n",
    "\n",
    "rt, X_train_new, y_train_new = ADASYNOversampling(X_train=X_train, y_train=y_train)\n",
    "\n",
    "print(\"y train ratio: 1:\" + str(round(y_train_new.value_counts()[0] / y_train_new.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new, y_train_new)\n",
    "clf_KNN.fit(X_train_new, y_train_new)\n",
    "clf_LR.fit(X_train_new, y_train_new)\n",
    "clf_DT.fit(X_train_new, y_train_new)\n",
    "clf_RF.fit(X_train_new, y_train_new)\n",
    "clf_LightGBM.fit(X_train_new, y_train_new)\n",
    "clf_Adaboost.fit(X_train_new, y_train_new)\n",
    "clf_GBDT.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe407783",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/JS_Vuln_res.csv\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"ADASYN\", rt, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"ADASYN\", rt, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"ADASYN\", rt, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"ADASYN\", rt, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"ADASYN\", rt, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"ADASYN\", rt, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"ADASYN\", rt, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"ADASYN\", rt, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce42c3ba",
   "metadata": {},
   "source": [
    "### BorderlineSMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb8c575a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train ratio: 1:1\n"
     ]
    }
   ],
   "source": [
    "# BorderlineSMOTE oversampling run - BorderlineSMOTE oversampling technique\n",
    "# inputs: X_train_random, y_train_random, X_test, y_test\n",
    "\n",
    "rt, X_train_new, y_train_new = BorderlineSMOTEOversampling(X_train=X_train, y_train=y_train)\n",
    "\n",
    "print(\"y train ratio: 1:\" + str(round(y_train_new.value_counts()[0] / y_train_new.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new, y_train_new)\n",
    "clf_KNN.fit(X_train_new, y_train_new)\n",
    "clf_LR.fit(X_train_new, y_train_new)\n",
    "clf_DT.fit(X_train_new, y_train_new)\n",
    "clf_RF.fit(X_train_new, y_train_new)\n",
    "clf_LightGBM.fit(X_train_new, y_train_new)\n",
    "clf_Adaboost.fit(X_train_new, y_train_new)\n",
    "clf_GBDT.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66b618da",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/JS_Vuln_res.csv\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"BorderlineSMOTE\", rt, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"BorderlineSMOTE\", rt, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"BorderlineSMOTE\", rt, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"BorderlineSMOTE\", rt, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"BorderlineSMOTE\", rt, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"BorderlineSMOTE\", rt, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"BorderlineSMOTE\", rt, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"BorderlineSMOTE\", rt, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da57b03",
   "metadata": {},
   "source": [
    "### SMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dcb9692b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train ratio: 1:1\n"
     ]
    }
   ],
   "source": [
    "# SMOTE oversampling run - SMOTE oversampling technique\n",
    "# inputs: X_train_random, y_train_random, X_test, y_test\n",
    "\n",
    "rt, X_train_new, y_train_new = SMOTEOversampling(X_train=X_train, y_train=y_train)\n",
    "\n",
    "print(\"y train ratio: 1:\" + str(round(y_train_new.value_counts()[0] / y_train_new.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new, y_train_new)\n",
    "clf_KNN.fit(X_train_new, y_train_new)\n",
    "clf_LR.fit(X_train_new, y_train_new)\n",
    "clf_DT.fit(X_train_new, y_train_new)\n",
    "clf_RF.fit(X_train_new, y_train_new)\n",
    "clf_LightGBM.fit(X_train_new, y_train_new)\n",
    "clf_Adaboost.fit(X_train_new, y_train_new)\n",
    "clf_GBDT.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25575924",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/JS_Vuln_res.csv\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"SMOTE\", rt, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"SMOTE\", rt, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"SMOTE\", rt, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"SMOTE\", rt, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"SMOTE\", rt, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"SMOTE\", rt, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"SMOTE\", rt, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"SMOTE\", rt, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5664b3c0",
   "metadata": {},
   "source": [
    "### SVMSMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b215bd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train ratio: 1:1\n"
     ]
    }
   ],
   "source": [
    "# SVMSMOTE oversampling run - SVMSMOTE oversampling technique\n",
    "# inputs: X_train_random, y_train_random, X_test, y_test\n",
    "\n",
    "rt, X_train_new, y_train_new = SVMSMOTEOversampling(X_train=X_train, y_train=y_train)\n",
    "\n",
    "print(\"y train ratio: 1:\" + str(round(y_train_new.value_counts()[0] / y_train_new.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new, y_train_new)\n",
    "clf_KNN.fit(X_train_new, y_train_new)\n",
    "clf_LR.fit(X_train_new, y_train_new)\n",
    "clf_DT.fit(X_train_new, y_train_new)\n",
    "clf_RF.fit(X_train_new, y_train_new)\n",
    "clf_LightGBM.fit(X_train_new, y_train_new)\n",
    "clf_Adaboost.fit(X_train_new, y_train_new)\n",
    "clf_GBDT.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23e74523",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/JS_Vuln_res.csv\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"SVMSMOTE\", rt, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"SVMSMOTE\", rt, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"SVMSMOTE\", rt, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"SVMSMOTE\", rt, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"SVMSMOTE\", rt, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"SVMSMOTE\", rt, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"SVMSMOTE\", rt, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"SVMSMOTE\", rt, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3213ef0",
   "metadata": {},
   "source": [
    "### SMOTUNED Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e6930f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train ratio of SVM: 1:1\n",
      "y train ratio of KNN: 1:1\n",
      "y train ratio of LR: 1:1\n",
      "y train ratio of DT: 1:1\n",
      "y train ratio of RF: 1:1\n",
      "y train ratio of LightGBM: 1:1\n",
      "y train ratio of Adaboost: 1:1\n",
      "y train ratio of GBDT: 1:1\n"
     ]
    }
   ],
   "source": [
    "# SMOTUNED oversampling run - SMOTUNED oversampling technique\n",
    "# inputs: X_train_random, y_train_random, X_test, y_test\n",
    "\n",
    "rt_SVM, X_train_new_SVM, y_train_new_SVM = SMOTUNEDOversampling(X_train=X_train, X_test=X_test, \n",
    "                                                                y_train=y_train, y_test=y_test, model=\"SVM\")\n",
    "print(\"y train ratio of SVM: 1:\" + str(round(y_train_new_SVM.value_counts()[0] / y_train_new_SVM.value_counts()[1])))\n",
    "\n",
    "rt_KNN, X_train_new_KNN, y_train_new_KNN = SMOTUNEDOversampling(X_train=X_train, X_test=X_test, \n",
    "                                                                y_train=y_train, y_test=y_test, model=\"KNN\")\n",
    "print(\"y train ratio of KNN: 1:\" + str(round(y_train_new_KNN.value_counts()[0] / y_train_new_KNN.value_counts()[1])))\n",
    "\n",
    "rt_LR, X_train_new_LR, y_train_new_LR = SMOTUNEDOversampling(X_train=X_train, X_test=X_test, \n",
    "                                                             y_train=y_train, y_test=y_test, model=\"LR\")\n",
    "print(\"y train ratio of LR: 1:\" + str(round(y_train_new_LR.value_counts()[0] / y_train_new_LR.value_counts()[1])))\n",
    "\n",
    "rt_DT, X_train_new_DT, y_train_new_DT = SMOTUNEDOversampling(X_train=X_train, X_test=X_test, \n",
    "                                                             y_train=y_train, y_test=y_test, model=\"DT\")\n",
    "print(\"y train ratio of DT: 1:\" + str(round(y_train_new_DT.value_counts()[0] / y_train_new_DT.value_counts()[1])))\n",
    "\n",
    "rt_RF, X_train_new_RF, y_train_new_RF = SMOTUNEDOversampling(X_train=X_train, X_test=X_test, \n",
    "                                                             y_train=y_train, y_test=y_test, model=\"RF\")\n",
    "print(\"y train ratio of RF: 1:\" + str(round(y_train_new_RF.value_counts()[0] / y_train_new_RF.value_counts()[1])))\n",
    "\n",
    "rt_LightGBM, X_train_new_LightGBM, y_train_new_LightGBM = SMOTUNEDOversampling(X_train=X_train, X_test=X_test, \n",
    "                                                                               y_train=y_train, y_test=y_test, model=\"LightGBM\")\n",
    "print(\"y train ratio of LightGBM: 1:\" + str(round(y_train_new_LightGBM.value_counts()[0] / y_train_new_LightGBM.value_counts()[1])))\n",
    "\n",
    "rt_Adaboost, X_train_new_Adaboost, y_train_new_Adaboost = SMOTUNEDOversampling(X_train=X_train, X_test=X_test, \n",
    "                                                                               y_train=y_train, y_test=y_test, model=\"Adaboost\")\n",
    "print(\"y train ratio of Adaboost: 1:\" + str(round(y_train_new_Adaboost.value_counts()[0] / y_train_new_Adaboost.value_counts()[1])))\n",
    "\n",
    "rt_GBDT, X_train_new_GBDT, y_train_new_GBDT = SMOTUNEDOversampling(X_train=X_train, X_test=X_test, \n",
    "                                                                   y_train=y_train, y_test=y_test, model=\"GBDT\")\n",
    "print(\"y train ratio of GBDT: 1:\" + str(round(y_train_new_GBDT.value_counts()[0] / y_train_new_GBDT.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new_SVM, y_train_new_SVM)\n",
    "clf_KNN.fit(X_train_new_KNN, y_train_new_KNN)\n",
    "clf_LR.fit(X_train_new_LR, y_train_new_LR)\n",
    "clf_DT.fit(X_train_new_DT, y_train_new_DT)\n",
    "clf_RF.fit(X_train_new_RF, y_train_new_RF)\n",
    "clf_LightGBM.fit(X_train_new_LightGBM, y_train_new_LightGBM)\n",
    "clf_Adaboost.fit(X_train_new_Adaboost, y_train_new_Adaboost)\n",
    "clf_GBDT.fit(X_train_new_GBDT, y_train_new_GBDT)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f30df2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/JS_Vuln_res.csv\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"SMOTUNED\", rt_SVM, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"SMOTUNED\", rt_KNN, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"SMOTUNED\", rt_LR, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"SMOTUNED\", rt_DT, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"SMOTUNED\", rt_RF, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"SMOTUNED\", rt_LightGBM, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"SMOTUNED\", rt_Adaboost, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"SMOTUNED\", rt_GBDT, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a843797b",
   "metadata": {},
   "source": [
    "### DAZZLE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f2a186e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                           | 0/100 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-07 14:33:25.756658: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-07 14:33:25.758365: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 100/100 [00:47<00:00,  2.09trial/s, best loss: -0.9074079856732415]\n",
      "Best Hyperparameters: {'batch_size': 16, 'discriminator_activation_fn': <function relu at 0x7fd4583689d0>, 'discriminator_layer_normalization': True, 'discriminator_lr': 0.005861854470139931, 'discriminator_optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'epochs': 10, 'generator_activation_fn': <function leaky_relu at 0x7fd3c42d1550>, 'generator_layer_normalization': False, 'generator_lr': 0.0005962450444945657, 'generator_optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>}\n",
      "Best G-Measure: 0.9074079856732415\n",
      " 27/157 [====>.........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step\n",
      "y train ratio: 1:1\n"
     ]
    }
   ],
   "source": [
    "# DAZZLE oversampling run - DAZZLE oversampling technique\n",
    "# inputs: X_train_random, y_train_random, X_test, y_test\n",
    "\n",
    "rt, X_train_new, y_train_new = DAZZLEOversampling(X_train=X_train, y_train=y_train)\n",
    "\n",
    "print(\"y train ratio: 1:\" + str(round(y_train_new.value_counts()[0] / y_train_new.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new, y_train_new)\n",
    "clf_KNN.fit(X_train_new, y_train_new)\n",
    "clf_LR.fit(X_train_new, y_train_new)\n",
    "clf_DT.fit(X_train_new, y_train_new)\n",
    "clf_RF.fit(X_train_new, y_train_new)\n",
    "clf_LightGBM.fit(X_train_new, y_train_new)\n",
    "clf_Adaboost.fit(X_train_new, y_train_new)\n",
    "clf_GBDT.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc36476a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/JS_Vuln_res.csv\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"DAZZLE\", rt, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"DAZZLE\", rt, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"DAZZLE\", rt, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"DAZZLE\", rt, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"DAZZLE\", rt, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"DAZZLE\", rt, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"DAZZLE\", rt, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"DAZZLE\", rt, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b81b7cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX CLASS 4293\n",
      "CLASS ID 1\n",
      "Epoch 1/150 completed. Gen loss: 0.026012679561972618. Desc loss_real: -0.009756787680089474. Desc loss_fake: -0.026012679561972618\n",
      "Epoch 51/150 completed. Gen loss: -0.0012427280889824033. Desc loss_real: 0.003576418850570917. Desc loss_fake: 0.0012427280889824033\n",
      "Epoch 101/150 completed. Gen loss: 1.1219585758226458e-05. Desc loss_real: 0.0019181367242708802. Desc loss_fake: -1.1219585758226458e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/e/Research/SyntheticData/src/data_imbalance_src/Imbalance_Farou2022/data_generation.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data = new_data.append(synthetic_data)\n",
      "/mnt/e/Research/SyntheticData/src/data_imbalance_src/Imbalance_Farou2022/data_generation.py:133: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  X_sample = X_sample.append(X_train)\n",
      "/mnt/e/Research/SyntheticData/src/data_imbalance_src/Imbalance_Farou2022/data_generation.py:135: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  X_sample = X_sample.drop(tar, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train ratio: 1:1\n"
     ]
    }
   ],
   "source": [
    "# WGAN oversampling run - WGAN oversampling technique\n",
    "# inputs: X_train_random, y_train_random, X_test, y_test\n",
    "\n",
    "rt, X_train_new, y_train_new = GANOversampling(X_train=X_train, y_train=y_train)\n",
    "\n",
    "print(\"y train ratio: 1:\" + str(round(y_train_new.value_counts()[0] / y_train_new.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new, y_train_new)\n",
    "clf_KNN.fit(X_train_new, y_train_new)\n",
    "clf_LR.fit(X_train_new, y_train_new)\n",
    "clf_DT.fit(X_train_new, y_train_new)\n",
    "clf_RF.fit(X_train_new, y_train_new)\n",
    "clf_LightGBM.fit(X_train_new, y_train_new)\n",
    "clf_Adaboost.fit(X_train_new, y_train_new)\n",
    "clf_GBDT.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7ee89a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/JS_Vuln_res.csv\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"WGAN\", rt, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"WGAN\", rt, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"WGAN\", rt, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"WGAN\", rt, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"WGAN\", rt, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"WGAN\", rt, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"WGAN\", rt, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"WGAN\", rt, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259ab89b",
   "metadata": {},
   "source": [
    "### Diveplane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e042847",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
