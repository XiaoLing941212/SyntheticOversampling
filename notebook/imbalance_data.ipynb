{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce7a99e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sys.path.insert(0, f\"{os.path.dirname(os.getcwd())}/src\")\n",
    "from utils import evaluate_result\n",
    "from data_imbalance_src.smote_oversampling import RandomOversampling, ADASYNOversampling, BorderlineSMOTEOversampling, SMOTEOversampling, SVMSMOTEOversampling\n",
    "from data_imbalance_src.smote_oversampling import SMOTUNEDOversampling\n",
    "from data_imbalance_src.dazzle import DAZZLEOversampling\n",
    "from data_imbalance_src.Imbalance_Farou2022.data_generation import GANOversampling\n",
    "from data_imbalance_src.random_projection import RandomProjectionOversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15e31aa",
   "metadata": {},
   "source": [
    "# JavaScript_Vulnerability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8572f1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_path = f\"{os.path.dirname(os.getcwd())}/result/JS_Vuln_res.csv\"\n",
    "with open(write_path, \"w\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    csv_writer.writerow([\"oversampling_scheme\", \"runtime\", \"learner\", \"acc\", \"prec\", \"recall\", \"fpr\", \"f1\", \"auc\", \"g_score\", \"d2h\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7101bb32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JSVulnerabilityDataSet-1.0.csv']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = f\"{os.path.dirname(os.getcwd())}/data/JavaScript_Vulnerability/\"\n",
    "datafiles = [f for f in os.listdir(data_path) if f.endswith(\"csv\")]\n",
    "datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fdc3ec3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{data_path}/{datafiles[0]}\")\n",
    "drop_columns = [\"name\", \"longname\", \"path\", \"full_repo_path\", \"line\", \"column\", \"endline\", \"endcolumn\"]\n",
    "df = df.drop(drop_columns, axis=1)\n",
    "df = df.drop_duplicates()\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7cc3a2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y value counts: \n",
      " 0    5367\n",
      "1     904\n",
      "Name: Vuln, dtype: int64\n",
      "y class ratio: 1: 6\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "print(\"y value counts: \\n\", str(y.value_counts()))\n",
    "print(\"y class ratio: 1:\", str(round(y.value_counts()[0]/y.value_counts()[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d571f8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- y train classes count: \n",
      "0    4293\n",
      "1     723\n",
      "Name: Vuln, dtype: int64\n",
      "--- y train ratio: 1:6\n",
      " \n",
      "--- y test classes count: \n",
      "0    1074\n",
      "1     181\n",
      "Name: Vuln, dtype: int64\n",
      "--- y test ratio: 1:6\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scale = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X_scale, columns=X.columns, index=X.index)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "print(\"--- y train classes count: \\n\" + str(y_train.value_counts()))\n",
    "print(\"--- y train ratio: 1:\" + str(round(y_train.value_counts()[0] / y_train.value_counts()[1])))\n",
    "print(\" \")\n",
    "print(\"--- y test classes count: \\n\" + str(y_test.value_counts()))\n",
    "print(\"--- y test ratio: 1:\" + str(round(y_test.value_counts()[0] / y_test.value_counts()[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df258af4",
   "metadata": {},
   "source": [
    "### Normal Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29b12c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal run - without any oversampling technique\n",
    "# inputs: X_train, y_train, X_test, y_test\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train, y_train)\n",
    "clf_KNN.fit(X_train, y_train)\n",
    "clf_LR.fit(X_train, y_train)\n",
    "clf_DT.fit(X_train, y_train)\n",
    "clf_RF.fit(X_train, y_train)\n",
    "clf_LightGBM.fit(X_train, y_train)\n",
    "clf_Adaboost.fit(X_train, y_train)\n",
    "clf_GBDT.fit(X_train, y_train)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44724aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/JS_Vuln_res.csv\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"No\", 0, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"No\", 0, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"No\", 0, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"No\", 0, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"No\", 0, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"No\", 0, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"No\", 0, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"No\", 0, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30546253",
   "metadata": {},
   "source": [
    "### Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a614150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train ratio: 1:1\n"
     ]
    }
   ],
   "source": [
    "# random oversampling run - random oversampling technique\n",
    "# inputs: X_train_random, y_train_random, X_test, y_test\n",
    "\n",
    "rt, X_train_new, y_train_new = RandomOversampling(X_train=X_train, y_train=y_train)\n",
    "\n",
    "print(\"y train ratio: 1:\" + str(round(y_train_new.value_counts()[0] / y_train_new.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new, y_train_new)\n",
    "clf_KNN.fit(X_train_new, y_train_new)\n",
    "clf_LR.fit(X_train_new, y_train_new)\n",
    "clf_DT.fit(X_train_new, y_train_new)\n",
    "clf_RF.fit(X_train_new, y_train_new)\n",
    "clf_LightGBM.fit(X_train_new, y_train_new)\n",
    "clf_Adaboost.fit(X_train_new, y_train_new)\n",
    "clf_GBDT.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f267c738",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/JS_Vuln_res.csv\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"Random\", rt, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"Random\", rt, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"Random\", rt, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"Random\", rt, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"Random\", rt, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"Random\", rt, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"Random\", rt, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"Random\", rt, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66fdee4",
   "metadata": {},
   "source": [
    "### ADASYN Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6eae7cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train ratio: 1:1\n"
     ]
    }
   ],
   "source": [
    "# ADASYN oversampling run - ADASYN oversampling technique\n",
    "# inputs: X_train_random, y_train_random, X_test, y_test\n",
    "\n",
    "rt, X_train_new, y_train_new = ADASYNOversampling(X_train=X_train, y_train=y_train)\n",
    "\n",
    "print(\"y train ratio: 1:\" + str(round(y_train_new.value_counts()[0] / y_train_new.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new, y_train_new)\n",
    "clf_KNN.fit(X_train_new, y_train_new)\n",
    "clf_LR.fit(X_train_new, y_train_new)\n",
    "clf_DT.fit(X_train_new, y_train_new)\n",
    "clf_RF.fit(X_train_new, y_train_new)\n",
    "clf_LightGBM.fit(X_train_new, y_train_new)\n",
    "clf_Adaboost.fit(X_train_new, y_train_new)\n",
    "clf_GBDT.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "302601b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/JS_Vuln_res.csv\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"ADASYN\", rt, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"ADASYN\", rt, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"ADASYN\", rt, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"ADASYN\", rt, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"ADASYN\", rt, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"ADASYN\", rt, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"ADASYN\", rt, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"ADASYN\", rt, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe6f18f",
   "metadata": {},
   "source": [
    "### BorderlineSMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44840ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train ratio: 1:1\n"
     ]
    }
   ],
   "source": [
    "# BorderlineSMOTE oversampling run - BorderlineSMOTE oversampling technique\n",
    "# inputs: X_train_random, y_train_random, X_test, y_test\n",
    "\n",
    "rt, X_train_new, y_train_new = BorderlineSMOTEOversampling(X_train=X_train, y_train=y_train)\n",
    "\n",
    "print(\"y train ratio: 1:\" + str(round(y_train_new.value_counts()[0] / y_train_new.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new, y_train_new)\n",
    "clf_KNN.fit(X_train_new, y_train_new)\n",
    "clf_LR.fit(X_train_new, y_train_new)\n",
    "clf_DT.fit(X_train_new, y_train_new)\n",
    "clf_RF.fit(X_train_new, y_train_new)\n",
    "clf_LightGBM.fit(X_train_new, y_train_new)\n",
    "clf_Adaboost.fit(X_train_new, y_train_new)\n",
    "clf_GBDT.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9577d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/JS_Vuln_res.csv\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"BorderlineSMOTE\", rt, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"BorderlineSMOTE\", rt, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"BorderlineSMOTE\", rt, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"BorderlineSMOTE\", rt, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"BorderlineSMOTE\", rt, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"BorderlineSMOTE\", rt, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"BorderlineSMOTE\", rt, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"BorderlineSMOTE\", rt, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e73e56",
   "metadata": {},
   "source": [
    "### SMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2fc6e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train ratio: 1:1\n"
     ]
    }
   ],
   "source": [
    "# SMOTE oversampling run - SMOTE oversampling technique\n",
    "# inputs: X_train_random, y_train_random, X_test, y_test\n",
    "\n",
    "rt, X_train_new, y_train_new = SMOTEOversampling(X_train=X_train, y_train=y_train)\n",
    "\n",
    "print(\"y train ratio: 1:\" + str(round(y_train_new.value_counts()[0] / y_train_new.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new, y_train_new)\n",
    "clf_KNN.fit(X_train_new, y_train_new)\n",
    "clf_LR.fit(X_train_new, y_train_new)\n",
    "clf_DT.fit(X_train_new, y_train_new)\n",
    "clf_RF.fit(X_train_new, y_train_new)\n",
    "clf_LightGBM.fit(X_train_new, y_train_new)\n",
    "clf_Adaboost.fit(X_train_new, y_train_new)\n",
    "clf_GBDT.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c325be90",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/JS_Vuln_res.csv\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"SMOTE\", rt, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"SMOTE\", rt, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"SMOTE\", rt, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"SMOTE\", rt, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"SMOTE\", rt, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"SMOTE\", rt, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"SMOTE\", rt, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"SMOTE\", rt, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b79038c",
   "metadata": {},
   "source": [
    "### SVMSMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3322c6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train ratio: 1:1\n"
     ]
    }
   ],
   "source": [
    "# SVMSMOTE oversampling run - SVMSMOTE oversampling technique\n",
    "# inputs: X_train_random, y_train_random, X_test, y_test\n",
    "\n",
    "rt, X_train_new, y_train_new = SVMSMOTEOversampling(X_train=X_train, y_train=y_train)\n",
    "\n",
    "print(\"y train ratio: 1:\" + str(round(y_train_new.value_counts()[0] / y_train_new.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new, y_train_new)\n",
    "clf_KNN.fit(X_train_new, y_train_new)\n",
    "clf_LR.fit(X_train_new, y_train_new)\n",
    "clf_DT.fit(X_train_new, y_train_new)\n",
    "clf_RF.fit(X_train_new, y_train_new)\n",
    "clf_LightGBM.fit(X_train_new, y_train_new)\n",
    "clf_Adaboost.fit(X_train_new, y_train_new)\n",
    "clf_GBDT.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c9b9446",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/JS_Vuln_res.csv\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"SVMSMOTE\", rt, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"SVMSMOTE\", rt, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"SVMSMOTE\", rt, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"SVMSMOTE\", rt, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"SVMSMOTE\", rt, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"SVMSMOTE\", rt, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"SVMSMOTE\", rt, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"SVMSMOTE\", rt, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0836568e",
   "metadata": {},
   "source": [
    "### SMOTUNED Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67c754b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train ratio of SVM: 1:1\n",
      "y train ratio of KNN: 1:1\n",
      "y train ratio of LR: 1:1\n",
      "y train ratio of DT: 1:1\n",
      "y train ratio of RF: 1:1\n",
      "y train ratio of LightGBM: 1:1\n",
      "y train ratio of Adaboost: 1:1\n",
      "y train ratio of GBDT: 1:1\n"
     ]
    }
   ],
   "source": [
    "# SMOTUNED oversampling run - SMOTUNED oversampling technique\n",
    "# inputs: X_train_random, y_train_random, X_test, y_test\n",
    "\n",
    "rt_SVM, X_train_new_SVM, y_train_new_SVM = SMOTUNEDOversampling(X_train=X_train, X_test=X_test, \n",
    "                                                                y_train=y_train, y_test=y_test, model=\"SVM\")\n",
    "print(\"y train ratio of SVM: 1:\" + str(round(y_train_new_SVM.value_counts()[0] / y_train_new_SVM.value_counts()[1])))\n",
    "\n",
    "rt_KNN, X_train_new_KNN, y_train_new_KNN = SMOTUNEDOversampling(X_train=X_train, X_test=X_test, \n",
    "                                                                y_train=y_train, y_test=y_test, model=\"KNN\")\n",
    "print(\"y train ratio of KNN: 1:\" + str(round(y_train_new_KNN.value_counts()[0] / y_train_new_KNN.value_counts()[1])))\n",
    "\n",
    "rt_LR, X_train_new_LR, y_train_new_LR = SMOTUNEDOversampling(X_train=X_train, X_test=X_test, \n",
    "                                                             y_train=y_train, y_test=y_test, model=\"LR\")\n",
    "print(\"y train ratio of LR: 1:\" + str(round(y_train_new_LR.value_counts()[0] / y_train_new_LR.value_counts()[1])))\n",
    "\n",
    "rt_DT, X_train_new_DT, y_train_new_DT = SMOTUNEDOversampling(X_train=X_train, X_test=X_test, \n",
    "                                                             y_train=y_train, y_test=y_test, model=\"DT\")\n",
    "print(\"y train ratio of DT: 1:\" + str(round(y_train_new_DT.value_counts()[0] / y_train_new_DT.value_counts()[1])))\n",
    "\n",
    "rt_RF, X_train_new_RF, y_train_new_RF = SMOTUNEDOversampling(X_train=X_train, X_test=X_test, \n",
    "                                                             y_train=y_train, y_test=y_test, model=\"RF\")\n",
    "print(\"y train ratio of RF: 1:\" + str(round(y_train_new_RF.value_counts()[0] / y_train_new_RF.value_counts()[1])))\n",
    "\n",
    "rt_LightGBM, X_train_new_LightGBM, y_train_new_LightGBM = SMOTUNEDOversampling(X_train=X_train, X_test=X_test, \n",
    "                                                                               y_train=y_train, y_test=y_test, model=\"LightGBM\")\n",
    "print(\"y train ratio of LightGBM: 1:\" + str(round(y_train_new_LightGBM.value_counts()[0] / y_train_new_LightGBM.value_counts()[1])))\n",
    "\n",
    "rt_Adaboost, X_train_new_Adaboost, y_train_new_Adaboost = SMOTUNEDOversampling(X_train=X_train, X_test=X_test, \n",
    "                                                                               y_train=y_train, y_test=y_test, model=\"Adaboost\")\n",
    "print(\"y train ratio of Adaboost: 1:\" + str(round(y_train_new_Adaboost.value_counts()[0] / y_train_new_Adaboost.value_counts()[1])))\n",
    "\n",
    "rt_GBDT, X_train_new_GBDT, y_train_new_GBDT = SMOTUNEDOversampling(X_train=X_train, X_test=X_test, \n",
    "                                                                   y_train=y_train, y_test=y_test, model=\"GBDT\")\n",
    "print(\"y train ratio of GBDT: 1:\" + str(round(y_train_new_GBDT.value_counts()[0] / y_train_new_GBDT.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new_SVM, y_train_new_SVM)\n",
    "clf_KNN.fit(X_train_new_KNN, y_train_new_KNN)\n",
    "clf_LR.fit(X_train_new_LR, y_train_new_LR)\n",
    "clf_DT.fit(X_train_new_DT, y_train_new_DT)\n",
    "clf_RF.fit(X_train_new_RF, y_train_new_RF)\n",
    "clf_LightGBM.fit(X_train_new_LightGBM, y_train_new_LightGBM)\n",
    "clf_Adaboost.fit(X_train_new_Adaboost, y_train_new_Adaboost)\n",
    "clf_GBDT.fit(X_train_new_GBDT, y_train_new_GBDT)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "701236c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/JS_Vuln_res.csv\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"SMOTUNED\", rt_SVM, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"SMOTUNED\", rt_KNN, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"SMOTUNED\", rt_LR, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"SMOTUNED\", rt_DT, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"SMOTUNED\", rt_RF, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"SMOTUNED\", rt_LightGBM, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"SMOTUNED\", rt_Adaboost, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"SMOTUNED\", rt_GBDT, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2ee17a",
   "metadata": {},
   "source": [
    "### DAZZLE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0bbd69fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                           | 0/100 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-07 14:33:25.756658: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-07 14:33:25.758365: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 100/100 [00:47<00:00,  2.09trial/s, best loss: -0.9074079856732415]\n",
      "Best Hyperparameters: {'batch_size': 16, 'discriminator_activation_fn': <function relu at 0x7fd4583689d0>, 'discriminator_layer_normalization': True, 'discriminator_lr': 0.005861854470139931, 'discriminator_optimizer': <class 'keras.src.optimizers.nadam.Nadam'>, 'epochs': 10, 'generator_activation_fn': <function leaky_relu at 0x7fd3c42d1550>, 'generator_layer_normalization': False, 'generator_lr': 0.0005962450444945657, 'generator_optimizer': <class 'keras.src.optimizers.rmsprop.RMSprop'>}\n",
      "Best G-Measure: 0.9074079856732415\n",
      " 27/157 [====>.........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step\n",
      "y train ratio: 1:1\n"
     ]
    }
   ],
   "source": [
    "# DAZZLE oversampling run - DAZZLE oversampling technique\n",
    "# inputs: X_train_random, y_train_random, X_test, y_test\n",
    "\n",
    "rt, X_train_new, y_train_new = DAZZLEOversampling(X_train=X_train, y_train=y_train)\n",
    "\n",
    "print(\"y train ratio: 1:\" + str(round(y_train_new.value_counts()[0] / y_train_new.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new, y_train_new)\n",
    "clf_KNN.fit(X_train_new, y_train_new)\n",
    "clf_LR.fit(X_train_new, y_train_new)\n",
    "clf_DT.fit(X_train_new, y_train_new)\n",
    "clf_RF.fit(X_train_new, y_train_new)\n",
    "clf_LightGBM.fit(X_train_new, y_train_new)\n",
    "clf_Adaboost.fit(X_train_new, y_train_new)\n",
    "clf_GBDT.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "084bf85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/JS_Vuln_res.csv\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"DAZZLE\", rt, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"DAZZLE\", rt, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"DAZZLE\", rt, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"DAZZLE\", rt, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"DAZZLE\", rt, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"DAZZLE\", rt, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"DAZZLE\", rt, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"DAZZLE\", rt, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b702777",
   "metadata": {},
   "source": [
    "### WGAN Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4254eae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX CLASS 4293\n",
      "CLASS ID 1\n",
      "Epoch 1/150 completed. Gen loss: 0.026012679561972618. Desc loss_real: -0.009756787680089474. Desc loss_fake: -0.026012679561972618\n",
      "Epoch 51/150 completed. Gen loss: -0.0012427280889824033. Desc loss_real: 0.003576418850570917. Desc loss_fake: 0.0012427280889824033\n",
      "Epoch 101/150 completed. Gen loss: 1.1219585758226458e-05. Desc loss_real: 0.0019181367242708802. Desc loss_fake: -1.1219585758226458e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/e/Research/SyntheticData/src/data_imbalance_src/Imbalance_Farou2022/data_generation.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data = new_data.append(synthetic_data)\n",
      "/mnt/e/Research/SyntheticData/src/data_imbalance_src/Imbalance_Farou2022/data_generation.py:133: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  X_sample = X_sample.append(X_train)\n",
      "/mnt/e/Research/SyntheticData/src/data_imbalance_src/Imbalance_Farou2022/data_generation.py:135: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  X_sample = X_sample.drop(tar, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train ratio: 1:1\n"
     ]
    }
   ],
   "source": [
    "# WGAN oversampling run - WGAN oversampling technique\n",
    "# inputs: X_train_random, y_train_random, X_test, y_test\n",
    "\n",
    "rt, X_train_new, y_train_new = GANOversampling(X_train=X_train, y_train=y_train)\n",
    "\n",
    "print(\"y train ratio: 1:\" + str(round(y_train_new.value_counts()[0] / y_train_new.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new, y_train_new)\n",
    "clf_KNN.fit(X_train_new, y_train_new)\n",
    "clf_LR.fit(X_train_new, y_train_new)\n",
    "clf_DT.fit(X_train_new, y_train_new)\n",
    "clf_RF.fit(X_train_new, y_train_new)\n",
    "clf_LightGBM.fit(X_train_new, y_train_new)\n",
    "clf_Adaboost.fit(X_train_new, y_train_new)\n",
    "clf_GBDT.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1a9bf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/JS_Vuln_res.csv\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"WGAN\", rt, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"WGAN\", rt, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"WGAN\", rt, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"WGAN\", rt, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"WGAN\", rt, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"WGAN\", rt, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"WGAN\", rt, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"WGAN\", rt, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d298d7db",
   "metadata": {},
   "source": [
    "### Random Projection Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "765fc1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train ratio: 1:1\n"
     ]
    }
   ],
   "source": [
    "# Random projection oversampling run - Random projection oversampling technique\n",
    "# inputs: X_train_random, y_train_random, X_test, y_test\n",
    "\n",
    "rt, X_train_new, y_train_new = RandomProjectionOversampling(X_train=X_train, y_train=y_train)\n",
    "\n",
    "print(\"y train ratio: 1:\" + str(round(y_train_new.value_counts()[0] / y_train_new.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new, y_train_new)\n",
    "clf_KNN.fit(X_train_new, y_train_new)\n",
    "clf_LR.fit(X_train_new, y_train_new)\n",
    "clf_DT.fit(X_train_new, y_train_new)\n",
    "clf_RF.fit(X_train_new, y_train_new)\n",
    "clf_LightGBM.fit(X_train_new, y_train_new)\n",
    "clf_Adaboost.fit(X_train_new, y_train_new)\n",
    "clf_GBDT.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71dce7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/JS_Vuln_res.csv\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"RP\", rt, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"RP\", rt, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"RP\", rt, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"RP\", rt, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"RP\", rt, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"RP\", rt, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"RP\", rt, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"RP\", rt, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496c3881",
   "metadata": {},
   "source": [
    "### Diveplane Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "610ebead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diveplane.utilities import infer_feature_attributes\n",
    "from diveplane.geminai import Geminai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69bd9c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/diveplane/geminai/base.py:376: UserWarning: The value of the parameter `generate_new_cases` is set as 'no' and not 'always', which means it is possible that some cases that are very similar to the original data may be returned. To prevent this from happening, please set generate_new_cases to 'always'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tar = y_train.name\n",
    "conditions = [{tar: 1},\n",
    "              {tar: 0}] * (int(X_train.shape[0] / 2))\n",
    "\n",
    "X_train[tar] = y_train\n",
    "partial_features = {\"CLLC\": {'type': \"continuous\"}}\n",
    "features = infer_feature_attributes(X_train, features=partial_features)\n",
    "for f_name, f_value in features.items():\n",
    "    if f_value[\"type\"] == \"nominal\":\n",
    "        f_value[\"non_sensitive\"] = True\n",
    "\n",
    "start_time = time.time()\n",
    "g = Geminai()\n",
    "g.train(X_train, features=features)\n",
    "\n",
    "gen_df = g.synthesize_cases(\n",
    "    n_samples=len(conditions),\n",
    "    case_context_values_maps=conditions,\n",
    "    generate_new_cases=\"no\"\n",
    ")\n",
    "\n",
    "rt = time.time() - start_time\n",
    "\n",
    "X_train = X_train.iloc[:, :-1]\n",
    "X_train_new = gen_df.iloc[:, :-1]\n",
    "y_train_new = gen_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "303463a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train ratio: 1:1\n"
     ]
    }
   ],
   "source": [
    "print(\"y train ratio: 1:\" + str(round(y_train_new.value_counts()[0] / y_train_new.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new, y_train_new)\n",
    "clf_KNN.fit(X_train_new, y_train_new)\n",
    "clf_LR.fit(X_train_new, y_train_new)\n",
    "clf_DT.fit(X_train_new, y_train_new)\n",
    "clf_RF.fit(X_train_new, y_train_new)\n",
    "clf_LightGBM.fit(X_train_new, y_train_new)\n",
    "clf_Adaboost.fit(X_train_new, y_train_new)\n",
    "clf_GBDT.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c458c7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/JS_Vuln_res.csv\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"Diveplane\", rt, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"Diveplane\", rt, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"Diveplane\", rt, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"Diveplane\", rt, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"Diveplane\", rt, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"Diveplane\", rt, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"Diveplane\", rt, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"Diveplane\", rt, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fb97a5",
   "metadata": {},
   "source": [
    "### DS Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70a5bec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataSynthesizer.DataDescriber import DataDescriber\n",
    "from DataSynthesizer.DataGenerator import DataGenerator\n",
    "from DataSynthesizer.ModelInspector import ModelInspector\n",
    "from DataSynthesizer.lib.utils import read_json_file, display_bayesian_network\n",
    "mode = \"independent_attribute_mode\"\n",
    "\n",
    "col = X_train.columns\n",
    "tar = y_train.name\n",
    "X_train[tar] = y_train\n",
    "write_df = X_train[X_train[tar] == 1]\n",
    "write_df = write_df.iloc[:, :-1]\n",
    "write_df.to_csv(f\"{os.path.dirname(os.getcwd())}/extra/js_vuln_pos_df.csv\", index=False)\n",
    "X_train = X_train.iloc[:, :-1]\n",
    "\n",
    "threshold = 20\n",
    "num_tuples_to_generate = int(y_train.value_counts()[0] - y_train.value_counts()[1])\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "description_file = f\"{os.path.dirname(os.getcwd())}/extra/js_vuln.json\"\n",
    "describer = DataDescriber(category_threshold=threshold)\n",
    "describer.describe_dataset_in_independent_attribute_mode(\n",
    "    dataset_file=f\"{os.path.dirname(os.getcwd())}/extra/js_vuln_pos_df.csv\"\n",
    ")\n",
    "describer.save_dataset_description_to_file(description_file)\n",
    "\n",
    "generator = DataGenerator()\n",
    "generator.generate_dataset_in_independent_mode(num_tuples_to_generate, description_file)\n",
    "generator.save_synthetic_data(f\"{os.path.dirname(os.getcwd())}/extra/js_vuln_syn_df.csv\")\n",
    "\n",
    "rt = time.time() - start_time\n",
    "\n",
    "X_train_new = pd.read_csv(f\"{os.path.dirname(os.getcwd())}/extra/js_vuln_syn_df.csv\").to_numpy()\n",
    "y_train_new = np.ones(num_tuples_to_generate)\n",
    "X_train_new = pd.DataFrame(np.vstack((X_train.to_numpy(), X_train_new)), columns=col)\n",
    "y_train_new = pd.Series(np.hstack((y_train.to_numpy(), y_train_new)), name=tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3243e801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train ratio: 1:1\n"
     ]
    }
   ],
   "source": [
    "print(\"y train ratio: 1:\" + str(round(y_train_new.value_counts()[0] / y_train_new.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new, y_train_new)\n",
    "clf_KNN.fit(X_train_new, y_train_new)\n",
    "clf_LR.fit(X_train_new, y_train_new)\n",
    "clf_DT.fit(X_train_new, y_train_new)\n",
    "clf_RF.fit(X_train_new, y_train_new)\n",
    "clf_LightGBM.fit(X_train_new, y_train_new)\n",
    "clf_Adaboost.fit(X_train_new, y_train_new)\n",
    "clf_GBDT.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e662c112",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/JS_Vuln_res.csv\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"DS\", rt, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"DS\", rt, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"DS\", rt, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"DS\", rt, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"DS\", rt, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"DS\", rt, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"DS\", rt, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"DS\", rt, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b78c147",
   "metadata": {},
   "source": [
    "### SDV Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8cec980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.metadata import SingleTableMetadata\n",
    "from sdv.lite import SingleTablePreset\n",
    "from sdv.single_table import CTGANSynthesizer\n",
    "from sdv.single_table import GaussianCopulaSynthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d242a743",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = X_train.columns\n",
    "tar = y_train.name\n",
    "num_tuples_to_generate = int(y_train.value_counts()[0] - y_train.value_counts()[1])\n",
    "X_train[tar] = y_train\n",
    "pos_df = X_train[X_train[tar] == 1]\n",
    "pos_df = pos_df.iloc[:, :-1]\n",
    "X_train = X_train.iloc[:, :-1]\n",
    "\n",
    "metadata = SingleTableMetadata()\n",
    "metadata.detect_from_dataframe(data=pos_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c95a1094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train ratio: 1:1\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "syn1 = SingleTablePreset(metadata, name=\"FAST_ML\")\n",
    "syn1.fit(data=pos_df)\n",
    "X_train_new = syn1.sample(num_rows=num_tuples_to_generate).to_numpy()\n",
    "\n",
    "rt = time.time() - start_time\n",
    "\n",
    "X_train_new = pd.DataFrame(np.vstack((X_train.to_numpy(), X_train_new)), columns=col)\n",
    "y_train_new = np.ones(num_tuples_to_generate)\n",
    "y_train_new = pd.Series(np.hstack((y_train.to_numpy(), y_train_new)), name=tar)\n",
    "\n",
    "print(\"y train ratio: 1:\" + str(round(y_train_new.value_counts()[0] / y_train_new.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new, y_train_new)\n",
    "clf_KNN.fit(X_train_new, y_train_new)\n",
    "clf_LR.fit(X_train_new, y_train_new)\n",
    "clf_DT.fit(X_train_new, y_train_new)\n",
    "clf_RF.fit(X_train_new, y_train_new)\n",
    "clf_LightGBM.fit(X_train_new, y_train_new)\n",
    "clf_Adaboost.fit(X_train_new, y_train_new)\n",
    "clf_GBDT.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8dd06d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/JS_Vuln_res.csv\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"SDV_FASTML\", rt, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"SDV_FASTML\", rt, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"SDV_FASTML\", rt, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"SDV_FASTML\", rt, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"SDV_FASTML\", rt, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"SDV_FASTML\", rt, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"SDV_FASTML\", rt, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"SDV_FASTML\", rt, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f6b25927",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'CC'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'CCL'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'CCO'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'CI'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'CLC'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'McCC'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'NL'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'NLE'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'CD'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'CLOC'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'DLOC'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'TCD'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'TCLOC'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'LLOC'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'LOC'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'NOS'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'NUMPAR'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'TLLOC'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'TLOC'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'TNOS'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'HOR_D'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'HOR_T'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'HON_D'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'HON_T'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'HLEN'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'HVOC'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'HDIFF'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'HVOL'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'HEFF'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'HBUGS'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'HTIME'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'CYCL'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'PARAMS'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'CYCL_DENS'. Data will not be rounded.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train ratio: 1:1\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "syn2 = GaussianCopulaSynthesizer(metadata)\n",
    "syn2.fit(data=pos_df)\n",
    "X_train_new = syn2.sample(num_rows=num_tuples_to_generate).to_numpy()\n",
    "\n",
    "rt = time.time() - start_time\n",
    "\n",
    "X_train_new = pd.DataFrame(np.vstack((X_train.to_numpy(), X_train_new)), columns=col)\n",
    "y_train_new = np.ones(num_tuples_to_generate)\n",
    "y_train_new = pd.Series(np.hstack((y_train.to_numpy(), y_train_new)), name=tar)\n",
    "\n",
    "print(\"y train ratio: 1:\" + str(round(y_train_new.value_counts()[0] / y_train_new.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new, y_train_new)\n",
    "clf_KNN.fit(X_train_new, y_train_new)\n",
    "clf_LR.fit(X_train_new, y_train_new)\n",
    "clf_DT.fit(X_train_new, y_train_new)\n",
    "clf_RF.fit(X_train_new, y_train_new)\n",
    "clf_LightGBM.fit(X_train_new, y_train_new)\n",
    "clf_Adaboost.fit(X_train_new, y_train_new)\n",
    "clf_GBDT.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f02dc73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/JS_Vuln_res.csv\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"SDV_GC\", rt, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"SDV_GC\", rt, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"SDV_GC\", rt, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"SDV_GC\", rt, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"SDV_GC\", rt, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"SDV_GC\", rt, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"SDV_GC\", rt, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"SDV_GC\", rt, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffccc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'CC'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'CCL'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'CCO'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'CI'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'CLC'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'McCC'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'NL'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'NLE'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'CD'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'CLOC'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'DLOC'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'TCD'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'TCLOC'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'LLOC'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'LOC'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'NOS'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'NUMPAR'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'TLLOC'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'TLOC'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'TNOS'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'HOR_D'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'HOR_T'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'HON_D'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'HON_T'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'HLEN'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'HVOC'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'HDIFF'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'HVOL'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'HEFF'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'HBUGS'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'HTIME'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'CYCL'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'PARAMS'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/numerical.py:112: UserWarning: No rounding scheme detected for column 'CYCL_DENS'. Data will not be rounded.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/home/lingxiao/diveplane/lib/python3.8/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "syn3 = CTGANSynthesizer(metadata)\n",
    "syn3.fit(data=pos_df)\n",
    "X_train_new = syn3.sample(num_rows=num_tuples_to_generate).to_numpy()\n",
    "\n",
    "rt = time.time() - start_time\n",
    "\n",
    "X_train_new = pd.DataFrame(np.vstack((X_train.to_numpy(), X_train_new)), columns=col)\n",
    "y_train_new = np.ones(num_tuples_to_generate)\n",
    "y_train_new = pd.Series(np.hstack((y_train.to_numpy(), y_train_new)), name=tar)\n",
    "\n",
    "print(\"y train ratio: 1:\" + str(round(y_train_new.value_counts()[0] / y_train_new.value_counts()[1])))\n",
    "\n",
    "# create models\n",
    "clf_SVM = SVC()\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf_LR = LogisticRegression(random_state=42, solver=\"saga\", max_iter=20000, n_jobs=-1)\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_RF = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "clf_LightGBM = LGBMClassifier(objective=\"binary\", random_state=42, n_jobs=-1)\n",
    "clf_Adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_GBDT = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, random_state=42)\n",
    "\n",
    "clf_SVM.fit(X_train_new, y_train_new)\n",
    "clf_KNN.fit(X_train_new, y_train_new)\n",
    "clf_LR.fit(X_train_new, y_train_new)\n",
    "clf_DT.fit(X_train_new, y_train_new)\n",
    "clf_RF.fit(X_train_new, y_train_new)\n",
    "clf_LightGBM.fit(X_train_new, y_train_new)\n",
    "clf_Adaboost.fit(X_train_new, y_train_new)\n",
    "clf_GBDT.fit(X_train_new, y_train_new)\n",
    "\n",
    "y_pred_SVM = clf_SVM.predict(X_test)\n",
    "y_pred_KNN = clf_KNN.predict(X_test)\n",
    "y_pred_LR = clf_LR.predict(X_test)\n",
    "y_pred_DT = clf_DT.predict(X_test)\n",
    "y_pred_RF = clf_RF.predict(X_test)\n",
    "y_pred_LightGBM = clf_LightGBM.predict(X_test)\n",
    "y_pred_Adaboost = clf_Adaboost.predict(X_test)\n",
    "y_pred_GBDT = clf_GBDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef12230",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.path.dirname(os.getcwd())}/result/JS_Vuln_res.csv\", \"a\", newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    \n",
    "    csv_writer.writerow([\"SDV_GAN\", rt, \"SVM\"] + evaluate_result(y_pred_SVM, y_test))\n",
    "    csv_writer.writerow([\"SDV_GAN\", rt, \"KNN\"] + evaluate_result(y_pred_KNN, y_test))\n",
    "    csv_writer.writerow([\"SDV_GAN\", rt, \"LR\"] + evaluate_result(y_pred_LR, y_test))\n",
    "    csv_writer.writerow([\"SDV_GAN\", rt, \"DT\"] + evaluate_result(y_pred_DT, y_test))\n",
    "    csv_writer.writerow([\"SDV_GAN\", rt, \"RF\"] + evaluate_result(y_pred_RF, y_test))\n",
    "    csv_writer.writerow([\"SDV_GAN\", rt, \"LightGBM\"] + evaluate_result(y_pred_LightGBM, y_test))\n",
    "    csv_writer.writerow([\"SDV_GAN\", rt, \"Adaboost\"] + evaluate_result(y_pred_Adaboost, y_test))\n",
    "    csv_writer.writerow([\"SDV_GAN\", rt, \"GBDT\"] + evaluate_result(y_pred_GBDT, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da10ed4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
